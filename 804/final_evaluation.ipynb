{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamdanXI/nlp_adventure/blob/main/804/final_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Model"
      ],
      "metadata": {
        "id": "VEyKUWPRlMq6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rvIwH23h9A81"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import torch\n",
        "major_version, minor_version = torch.cuda.get_device_capability()\n",
        "# Must install separately since Colab has torch 2.2.1, which breaks packages\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "if major_version >= 8:\n",
        "    # Use this for new GPUs like Ampere, Hopper GPUs (RTX 30xx, RTX 40xx, A100, H100, L40)\n",
        "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
        "else:\n",
        "    # Use this for older GPUs (V100, Tesla T4, RTX 20xx)\n",
        "    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
        "pass\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"HamdanXI/newton_qa_tinyllama\", # \"unsloth/tinyllama\" for 16bit loading\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")\n",
        "\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Model Outputs"
      ],
      "metadata": {
        "id": "8XRU_DrUlG3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating Single Output\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"Who are you?\", # instruction\n",
        "        \"Newton\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HIQkpELlSnQ",
        "outputId": "fd74c89e-d20a-4468-8f7f-f4e8a5d9f7a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWho are you?\\n\\n### Input:\\nNewton\\n\\n### Response:\\nI am a man of science, and mathematics. I have devoted my life to the study of the natural world and the laws that govern it. I have made many discoveries and made many contributions to the field of physics. I have also written many books and articles on my work.\\n\\n\\n### Discuss']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating Multiple Outputs\n",
        "def generate_responses(character_name, instructions_list):\n",
        "    responses = []\n",
        "    for instruction in instructions_list:\n",
        "      inputs = tokenizer([alpaca_prompt.format(instruction, character_name,\"\",)], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "      outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True)\n",
        "      decoded_output = tokenizer.batch_decode(outputs)\n",
        "      responses.append(decoded_output)\n",
        "\n",
        "    return responses\n",
        "\n",
        "\n",
        "# Example usage\n",
        "character_name = \"Newton\"\n",
        "instructions_list = [\"Who are you?\", \"Where was you born?\", \"What are your hobbies?\", \"Why are you famous?\", \"Did you face challenges in your life?\", \"How did you become smart?\", \"How did you discover all those new things?\"]\n",
        "responses = generate_responses(character_name, instructions_list)\n",
        "\n",
        "# Print the responses\n",
        "for response in responses:\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgBRx18wmffq",
        "outputId": "89a29a3e-90de-414a-f8b5-0e53acd4f94a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWho are you?\\n\\n### Input:\\nNewton\\n\\n### Response:\\nI am a man of science, and mathematics. I have devoted my life to the study of the natural world and the laws that govern it. I have made many discoveries and made many contributions to the field of physics. I have also written many books and articles on my work.\\n\\n\\n### Discuss']\n",
            "['<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhere was you born?\\n\\n### Input:\\nNewton\\n\\n### Response:\\nNewton was born in Woolsthorne, England, on the 4th of April, 163362.</s>']\n",
            "['<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat are your hobbies?\\n\\n### Input:\\nNewton\\n\\n### Response:\\nMy hobbies are mathematics, physics, and astronomy.</s>']\n",
            "['<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhy are you famous?\\n\\n### Input:\\nNewton\\n\\n### Response:\\nI am famous because I have made many contributions to the field of mathematics, including the laws of motion and universal gravitation, which are still used today. I also developed the calculus, which is used in many fields, such as physics and engineering.</s>']\n",
            "[\"<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDid you face challenges in your life?\\n\\n### Input:\\nNewton\\n\\n### Response:\\nYes, I did. I faced many challenges in my life. One of the biggest challenges I faced was my father's death. He was a very important person in my life, and I was very close to him. He was also a great scientist, and I was inspired by his work. However\"]\n",
            "['<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nHow did you become smart?\\n\\n### Input:\\nNewton\\n\\n### Response:\\nI was born in a time when the world was in a state of chaos and confusion. I was surrounded by people who were struggling to understand the laws of motion and gravity. I was taught by a man who believed in the power of reason and logic. I was surrounded by people who were searching for answers to the']\n",
            "[\"<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nHow did you discover all those new things?\\n\\n### Input:\\nNewton\\n\\n### Response:\\nI was just curious about the nature of the universe, and I wanted to understand it better. I spent a lot of time reading and studying, and I eventually realized that there were a lot of things that I didn't understand. I realized that there must be a fundamental law that governs the universe, and I\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Extract Response only\n",
        "def response_extractor(responses):\n",
        "  final_responses = []\n",
        "  for response in responses:\n",
        "    string = ''.join([str(item) for item in response])\n",
        "    response_start = string.find(\"### Response:\\n\") + len(\"### Response:\\n\")\n",
        "    response_text = string[response_start:].strip()\n",
        "\n",
        "    # Check and remove \"\\n\\n\\n### Discuss\" if it's at the end of the response text\n",
        "    discuss_marker = \"\\n\\n\\n### Discuss\"\n",
        "    if response_text.endswith(discuss_marker):\n",
        "      # Remove the discuss marker from the end of the response text\n",
        "      response_text = response_text[:-len(discuss_marker)].strip()\n",
        "\n",
        "    # Store the extracted text\n",
        "    final_responses.append(response_text)\n",
        "\n",
        "  return final_responses"
      ],
      "metadata": {
        "id": "RF2phTdxokQS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_responses = response_extractor(responses)"
      ],
      "metadata": {
        "id": "GySXt8QVnudv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_responses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1KP6zpysVim",
        "outputId": "a3489500-da39-49ca-9557-73bf1ced77ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I am a man of science, and mathematics. I have devoted my life to the study of the natural world and the laws that govern it. I have made many discoveries and made many contributions to the field of physics. I have also written many books and articles on my work.',\n",
              " 'Newton was born in Woolsthorne, England, on the 4th of April, 163362.</s>',\n",
              " 'My hobbies are mathematics, physics, and astronomy.</s>',\n",
              " 'I am famous because I have made many contributions to the field of mathematics, including the laws of motion and universal gravitation, which are still used today. I also developed the calculus, which is used in many fields, such as physics and engineering.</s>',\n",
              " \"Yes, I did. I faced many challenges in my life. One of the biggest challenges I faced was my father's death. He was a very important person in my life, and I was very close to him. He was also a great scientist, and I was inspired by his work. However\",\n",
              " 'I was born in a time when the world was in a state of chaos and confusion. I was surrounded by people who were struggling to understand the laws of motion and gravity. I was taught by a man who believed in the power of reason and logic. I was surrounded by people who were searching for answers to the',\n",
              " \"I was just curious about the nature of the universe, and I wanted to understand it better. I spent a lot of time reading and studying, and I eventually realized that there were a lot of things that I didn't understand. I realized that there must be a fundamental law that governs the universe, and I\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Accuracy"
      ],
      "metadata": {
        "id": "s52Ok0SO8jtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wikipedia Retrieving"
      ],
      "metadata": {
        "id": "-p_w1j8plJxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's start by retrieving and processing the content of the Isaac Newton Wikipedia page\n",
        "# for entity identification and expansion. This will involve:\n",
        "# 1. Fetching the content of the Wikipedia page.\n",
        "# 2. Extracting relevant text sections that likely contain key entities.\n",
        "# 3. Identifying entities using a pre-trained NER model.\n",
        "# 4. Expanding the entity list with synonyms and related terms where applicable.\n",
        "\n",
        "# Step 1: Fetch the Wikipedia page content.\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def fetch_newton_wikipedia():\n",
        "    url = 'https://en.wikipedia.org/wiki/Isaac_Newton'\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.text\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Step 2: Extract relevant sections from the Wikipedia content.\n",
        "def extract_relevant_sections(html_content):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    text_sections = []\n",
        "\n",
        "    # Extract sections that likely contain relevant entities (e.g., biography, works)\n",
        "    for header in soup.find_all(['h2', 'h3']):\n",
        "        nextNode = header\n",
        "        section_text = \"\"\n",
        "        while True:\n",
        "            nextNode = nextNode.nextSibling\n",
        "            if nextNode is None:\n",
        "                break\n",
        "            if hasattr(nextNode, 'name'):\n",
        "                if nextNode.name == \"h2\":\n",
        "                    break\n",
        "                if nextNode.name in ['p', 'ul', 'li']:\n",
        "                    section_text += nextNode.text\n",
        "        if section_text:\n",
        "            text_sections.append(section_text)\n",
        "    return text_sections\n",
        "\n",
        "url = fetch_newton_wikipedia()\n",
        "fetch_newton_wikipedia_instructions = extract_relevant_sections(url)"
      ],
      "metadata": {
        "id": "xSzqXeNfjrLw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieve NER"
      ],
      "metadata": {
        "id": "9Gkc12IAyolV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_entities_from_responses(responses):\n",
        "    all_entities = []\n",
        "    for response in responses:\n",
        "        doc = nlp(response)\n",
        "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "        all_entities.extend(entities)\n",
        "\n",
        "    return all_entities\n",
        "\n",
        "model_entities = extract_entities_from_responses(final_responses)\n",
        "\n",
        "# Print out the entities and their types\n",
        "for entity in model_entities:\n",
        "    print(f\"Entity: {entity[0]}, Type: {entity[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7G8bkLpxXl3",
        "outputId": "7df39599-3e8c-465f-9cd4-14953cb69150"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: Newton, Type: ORG\n",
            "Entity: Woolsthorne, Type: GPE\n",
            "Entity: England, Type: GPE\n",
            "Entity: the 4th of April, 163362.</s, Type: DATE\n",
            "Entity: today, Type: DATE\n",
            "Entity: engineering.</s, Type: ORG\n",
            "Entity: One, Type: CARDINAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_entities_from_responses(responses):\n",
        "    all_entities = []\n",
        "    for response in responses:\n",
        "        doc = nlp(response)\n",
        "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "        all_entities.extend(entities)\n",
        "\n",
        "    return all_entities\n",
        "\n",
        "wiki_entities = extract_entities_from_responses(fetch_newton_wikipedia_instructions)"
      ],
      "metadata": {
        "id": "KSiKh_29z5vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare both NER, and Return Accuracy"
      ],
      "metadata": {
        "id": "bSY0zTfRyuHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_matching_ratio(model_entities, wiki_entities):\n",
        "    # Initialize a counter for matching entities\n",
        "    matching_entities_count = 0\n",
        "\n",
        "    # Convert wiki_entities to a set for faster lookup\n",
        "    wiki_entities_set = set(wiki_entities)\n",
        "\n",
        "    # Iterate through model entities to check for matches\n",
        "    for entity in model_entities:\n",
        "        if entity in wiki_entities_set:\n",
        "            matching_entities_count += 1\n",
        "\n",
        "    # Calculate the ratio\n",
        "    if len(model_entities) == 0:\n",
        "        return 0  # Avoid division by zero\n",
        "    matching_ratio = matching_entities_count / len(model_entities)\n",
        "\n",
        "    return matching_ratio\n",
        "\n",
        "matching_ratio = calculate_matching_ratio(model_entities, wiki_entities)\n",
        "print(f\"Matching Entities Ratio: {matching_ratio:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CE5-4JhkL9m",
        "outputId": "75ec3065-29ae-465d-9b5e-c6b7bcb8c842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matching Entities Ratio: 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Originality"
      ],
      "metadata": {
        "id": "X2VFRp6t8vt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def calculate_average_cosine_similarity(responses):\n",
        "    # Initialize a TF-IDF Vectorizer\n",
        "    vectorizer = TfidfVectorizer()\n",
        "\n",
        "    # Fit and transform the responses to a TF-IDF matrix\n",
        "    tfidf_matrix = vectorizer.fit_transform(responses)\n",
        "\n",
        "    # Calculate cosine similarity between all pairs of responses\n",
        "    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "    # Calculate the average similarity, excluding self-comparisons\n",
        "    n = similarity_matrix.shape[0]\n",
        "    avg_similarity = (np.sum(similarity_matrix) - n) / (n * (n - 1))\n",
        "\n",
        "    return avg_similarity\n",
        "\n",
        "average_similarity = calculate_average_cosine_similarity(final_responses)\n",
        "print(f\"Average Cosine Similarity: {average_similarity:.4f}\")"
      ],
      "metadata": {
        "id": "tAa13hJy8x1G",
        "outputId": "200446ab-3cc9-4833-a9e7-5721a1dcec0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Cosine Similarity: 0.1609\n"
          ]
        }
      ]
    }
  ]
}