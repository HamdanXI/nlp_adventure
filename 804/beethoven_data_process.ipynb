{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "624d410e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset saved to beethoven_qa_combined_dataset.json. Total entries: 328\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URLs of the JSON files\n",
    "urls = [\n",
    "    \"https://raw.githubusercontent.com/choosewhatulike/trainable-agents/main/data/gen_results/interview_single/Beethoven_chatgpt_result/2023-00-00-00-00-00.json\",\n",
    "    \"https://raw.githubusercontent.com/choosewhatulike/trainable-agents/main/data/gen_results/interview_single/Beethoven_vicuna-7b_result/2023-00-00-00-00-00.json\",\n",
    "    \"https://raw.githubusercontent.com/choosewhatulike/trainable-agents/main/data/gen_results/interview_single/Beethoven_sft_result/2023-00-00-00-00-00.json\",\n",
    "    \"https://raw.githubusercontent.com/choosewhatulike/trainable-agents/main/data/gen_results/interview_single/Beethoven_alpaca-7b_result/2023-00-00-00-00-00.json\"\n",
    "]\n",
    "\n",
    "# Initialize a list to hold the combined parallel dataset\n",
    "parallel_dataset = []\n",
    "\n",
    "# Function to process and append data\n",
    "def process_and_append_data(data):\n",
    "    for item in data:\n",
    "        question = item.get('question', \"No question found\")\n",
    "        answer = \"No answer found\"  # Default answer\n",
    "\n",
    "        # Check if 'reply' is present\n",
    "        if 'reply' in item:\n",
    "            reply = item['reply']\n",
    "            \n",
    "            # If 'reply' is a list, check if the first item has 'content'\n",
    "            if isinstance(reply, list) and len(reply) > 0 and 'content' in reply[0]:\n",
    "                answer = reply[0]['content']\n",
    "            # If 'reply' is a dictionary, directly access 'content'\n",
    "            elif isinstance(reply, dict) and 'content' in reply:\n",
    "                answer = reply['content']\n",
    "        \n",
    "        # Append the question and answer as a dict to the parallel dataset\n",
    "        parallel_dataset.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": answer\n",
    "        })\n",
    "\n",
    "# Loop through each URL\n",
    "for url in urls:\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Load JSON content\n",
    "        data = json.loads(response.text)\n",
    "        \n",
    "        # Process and append data to the parallel dataset\n",
    "        process_and_append_data(data)\n",
    "    else:\n",
    "        print(\"Failed to retrieve JSON file from\", url, \". Status code:\", response.status_code)\n",
    "\n",
    "# Save the combined parallel dataset to a JSON file\n",
    "file_path = 'beethoven_qa_combined_dataset.json'\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(parallel_dataset, f)\n",
    "\n",
    "print(f\"Combined dataset saved to {file_path}. Total entries: {len(parallel_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d195c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset saved to beethoven_interview_turns_combined_dataset.json. Total entries: 1023\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URLs of the JSON Lines files\n",
    "urls = [\n",
    "    \"https://raw.githubusercontent.com/choosewhatulike/trainable-agents/main/data/gen_results/interview_turns/multiturn_Beethoven_alpaca-7b_result/2023-00-00-00-00-00.jsonl\",\n",
    "    \"https://raw.githubusercontent.com/choosewhatulike/trainable-agents/main/data/gen_results/interview_turns/multiturn_Beethoven_chatgpt_result/2023-00-00-00-00-00.jsonl\",\n",
    "    \"https://raw.githubusercontent.com/choosewhatulike/trainable-agents/main/data/gen_results/interview_turns/multiturn_Beethoven_sft_result/2023-00-00-00-00-00.jsonl\",\n",
    "    \"https://raw.githubusercontent.com/choosewhatulike/trainable-agents/main/data/gen_results/interview_turns/multiturn_Beethoven_vicuna-7b_result/2023-00-00-00-00-00.jsonl\"\n",
    "]\n",
    "\n",
    "# Initialize a list to hold the combined parallel dataset\n",
    "parallel_dataset = []\n",
    "\n",
    "# Process each URL\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Split the response text by lines, as each line is a separate JSON string\n",
    "        lines = response.text.strip().split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            interview = json.loads(line)  # Parse each line as JSON\n",
    "            \n",
    "            # Iterate through the content, which contains turn-based dialogue\n",
    "            for turn in interview.get('content', []):\n",
    "                # Check if the turn is by the character (Beethoven) and has content\n",
    "                if turn.get('turn_role') == 'character' and turn.get('turn_content'):\n",
    "                    # Extract the content\n",
    "                    for content_piece in turn['turn_content']:\n",
    "                        if 'content' in content_piece:\n",
    "                            answer = content_piece['content']\n",
    "                            # Attempt to find the previous question by the interviewer\n",
    "                            question_index = interview['content'].index(turn) - 1\n",
    "                            if question_index >= 0:\n",
    "                                question_turn = interview['content'][question_index]\n",
    "                                if question_turn.get('turn_role') == 'interviewer' and question_turn.get('turn_content'):\n",
    "                                    for question_piece in question_turn['turn_content']:\n",
    "                                        if 'content' in question_piece:\n",
    "                                            question = question_piece['content']\n",
    "                                            # Append the question and answer pair to the dataset\n",
    "                                            parallel_dataset.append({\"question\": question, \"answer\": answer})\n",
    "    else:\n",
    "        print(\"Failed to retrieve JSON Lines file from\", url, \". Status code:\", response.status_code)\n",
    "\n",
    "# Save the combined parallel dataset to a JSON file\n",
    "file_path = 'beethoven_interview_turns_combined_dataset.json'\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(parallel_dataset, f)\n",
    "\n",
    "print(f\"Combined dataset saved to {file_path}. Total entries: {len(parallel_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "201fb94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved to beethoven_qa_merged_dataset.json. Total entries: 1351\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# File paths\n",
    "existing_dataset_path = 'beethoven_qa_combined_dataset.json'\n",
    "new_dataset_path = 'beethoven_interview_turns_combined_dataset.json'\n",
    "merged_dataset_path = 'beethoven_qa_merged_dataset.json'\n",
    "\n",
    "# Load the existing dataset\n",
    "with open(existing_dataset_path, 'r') as file:\n",
    "    existing_dataset = json.load(file)\n",
    "\n",
    "# Load the new dataset\n",
    "with open(new_dataset_path, 'r') as file:\n",
    "    new_dataset = json.load(file)\n",
    "\n",
    "# Append the entries from the new dataset to the existing dataset\n",
    "merged_dataset = existing_dataset + new_dataset\n",
    "\n",
    "# Save the merged dataset to a JSON file\n",
    "with open(merged_dataset_path, 'w') as file:\n",
    "    json.dump(merged_dataset, file)\n",
    "\n",
    "print(f\"Merged dataset saved to {merged_dataset_path}. Total entries: {len(merged_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c786844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               question  \\\n",
      "0                     What do you think of your father?   \n",
      "1                     What do you think of your mother?   \n",
      "2                                What is your interest?   \n",
      "3                              Where are you come from?   \n",
      "4                                 Who do you live with?   \n",
      "...                                                 ...   \n",
      "1346  I've always been fascinated by your music, esp...   \n",
      "1347  That's fascinating! Can you tell me more about...   \n",
      "1348  That's really interesting. Did your deafness a...   \n",
      "1349  That's incredible! It's amazing how you were a...   \n",
      "1350  That's truly remarkable! It's incredible how y...   \n",
      "\n",
      "                                                 answer  \n",
      "0     My father was a strict man, but he was also my...  \n",
      "1     My mother was a great influence on my life and...  \n",
      "2     My interest lies in music, my dear sir. It is ...  \n",
      "3     I hail from the city of Bonn in the Electorate...  \n",
      "4     My dear sir, I am afraid I am no longer among ...  \n",
      "...                                                 ...  \n",
      "1346  Ah, my deafness has certainly had an impact on...  \n",
      "1347  Well, as I mentioned earlier, my deafness has ...  \n",
      "1348  Yes, my deafness certainly made it more diffic...  \n",
      "1349  Yes, my deafness certainly made it more diffic...  \n",
      "1350  Yes, my deafness certainly influenced the them...  \n",
      "\n",
      "[1351 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming merged_dataset is your loaded dataset\n",
    "df = pd.DataFrame(merged_dataset, columns=['question', 'answer'])\n",
    "\n",
    "# Now, when you display df, the columns will be in the order you specified\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55e1b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your DataFrame to a CSV file\n",
    "df.to_csv('beethoven_qa_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef7447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
