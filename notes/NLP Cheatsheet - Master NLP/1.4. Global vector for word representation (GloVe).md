---
title: 1.4. Global vector for word representation (GloVe)
updated: 2023-10-12 14:11:37Z
created: 2023-10-12 07:51:31Z
latitude: 25.20484930
longitude: 55.27078280
altitude: 0.0000
---

**What is GloVe?**
GloVe aims to combine the SVD-based approach and the context-based skip-gram model.

**How to build a co-occurence matrix for GloVe? What can we calculate with such a matrix?**
Let X be a word-word co-occurence matrix (coefficients are the number of times word i appears in the context of word j). With this matrix, we can compute the probability of word i appearing in the context of word j: Pij = Xij / Xi

**How is GloVe built?**
After building the co-occurence matrix, GloVe computes the ratios of co-occurrence probabilities (non-zero). The intuition is that the word meanings are capture by the ratios of co-occurrence probabilities rather than the probabilities themselves. The global vector models the relationship between two words regarding to the third context word as:

$$
F(w_i, w_j, \tilde{w}_k) = \frac{p_{\text{co}}(\tilde{w}_k | w_i)}{p_{\text{co}}(\tilde{w}_k | w_j)}
$$
 
F is designed to be a function of the linear difference between two words wi and wj. It is an exponential function.

**What are the pros of GloVe?**
The GloVe model efficiently leverages global statistical information by training only on non-zero elements in a word-word co-occurence matrix, and produces a vector space with meaningful substructure.

**What is window classification and why is it important?**
Natural languages tend to use the same word for very different meanings and we typically need to know the context of the word usage to discriminate between meanings.

E.g.: 'to sanction' means depending on the context 'to permit' or 'to punish'

A sequence is a central word vector preceded and succeeded by context word vectors. The number of words in the context is also known as the context window size and varies depending on the problem being solved.

**How do window size relate to performance?**
Generally, narrower window size lead to better performance in syntactic tests while wider windows lead to better performance in semantic tests.