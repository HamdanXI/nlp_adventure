4.2.1. Disadvantages

## Challenges and Considerations related to parsing with CCGs

1. **Supervised Training: One WSJ CCG TreeBank**:
   - **Disadvantage**: Most CCG parsers, especially those that use machine learning techniques, require supervised training, which means they need annotated data. The Wall Street Journal (WSJ) CCG TreeBank is one of the few large-scale annotated resources available for CCG, but relying solely on one dataset can be limiting. Training on a single dataset can lead to models that are overly specialized to the peculiarities of that dataset, making them less generalizable to other kinds of texts or domains.

2. **Pipelined: Supertagger limited sequential context**:
   - **Disadvantage**: In a pipelined system, each component (like the supertagger) operates sequentially and independently. So, the supertagger assigns categories to words without full knowledge of the broader parsing context or the results of later parsing steps. This can lead to errors early on that propagate and amplify in later stages. The supertagger's context is limited, meaning it may not always make the best decisions if it doesn't have a broader view of the sentence.

3. **PP Ambiguity: Kim saw a man in the park with a telescope**:
   - **Disadvantage**: This sentence exemplifies prepositional phrase (PP) attachment ambiguity. The phrase "with a telescope" can modify different parts of the sentence:
     - Kim used a telescope to see a man in the park.
     - Kim saw a man who was holding a telescope in the park.
     - Kim saw a man in the park, and there was a telescope in the park too.
   Parsing models, including CCG parsers, can struggle with such ambiguities. While CCG provides a rich set of tools for representing syntactic and semantic relationships, it's not immune to the inherent ambiguities present in natural language.

4. **Joint Model: Transformer-based multitagger and chart parser**:
   - **Concept**: Instead of a pipelined approach, a joint model integrates multiple components into a unified system. By using a transformer-based architecture (like those in BERT, GPT, etc.), the model can capture a rich context when deciding on categories or parsing structures. In this setup, a multitagger might propose multiple possible categories for each word, and a chart parser can work in tandem, considering these options in the broader context of the whole sentence.
   - **Advantage**: By integrating the processes, the model can make more informed and contextually-aware decisions, potentially increasing accuracy and reducing the compounding of errors that can occur in pipelined systems.

In summary, while CCG offers a robust framework for linguistic analysis, practical implementations face challenges related to training data, system architecture, and inherent ambiguities in language. However, advancements like joint modeling and transformer architectures present promising avenues for addressing these challenges.

id: bae34dea9ce740f1bd176bef3d42d024
parent_id: e2821040640f4d118f246f0a40ecda56
created_time: 2023-10-12T14:06:28.516Z
updated_time: 2023-10-12T14:08:00.974Z
is_conflict: 0
latitude: 25.20484930
longitude: 55.27078280
altitude: 0.0000
author: 
source_url: 
is_todo: 0
todo_due: 0
todo_completed: 0
source: joplin-desktop
source_application: net.cozic.joplin-desktop
application_data: 
order: 0
user_created_time: 2023-10-12T14:06:28.516Z
user_updated_time: 2023-10-12T14:08:00.974Z
encryption_cipher_text: 
encryption_applied: 0
markup_language: 1
is_shared: 0
share_id: 
conflict_original_id: 
master_key_id: 
user_data: 
type_: 1