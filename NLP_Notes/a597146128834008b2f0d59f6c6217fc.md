1.2. SVD-based methods (distributional semantics)

Objective: Finding word embeddings that captures some notion of similarity.

**What is distributional semantics?**
The concept of representing the meaning of a word based on the context in which it usually appears. It is dense and can better capture similarity.

**How do SVD-based methods work?**
Loop over a massive dataset and accumulate word co-occurence counts in a matrix X. Then use SVD where the word vectors are the columns of U.

**What is latent semantic analysis (LSA)?**
LSA is a technique of analyzing relationships between a set of documents and the terms they contain by producing a set of concepts related to the documents and terms. To do so, we build a matrix whose coefficients are word counts per document and use SVD to reduce the number of rows while preserving the similarity structure among columns. To compare documents, we compute the cosine similarity between the column vectors representing them.

id: a597146128834008b2f0d59f6c6217fc
parent_id: c770b4c8b0e040869d78c13b780409ed
created_time: 2023-10-12T07:50:38.204Z
updated_time: 2023-10-12T08:33:00.649Z
is_conflict: 0
latitude: 25.20484930
longitude: 55.27078280
altitude: 0.0000
author: 
source_url: 
is_todo: 0
todo_due: 0
todo_completed: 0
source: joplin-desktop
source_application: net.cozic.joplin-desktop
application_data: 
order: 0
user_created_time: 2023-10-12T07:50:38.204Z
user_updated_time: 2023-10-12T08:33:00.649Z
encryption_cipher_text: 
encryption_applied: 0
markup_language: 1
is_shared: 0
share_id: 
conflict_original_id: 
master_key_id: 
user_data: 
type_: 1