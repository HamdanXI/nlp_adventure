{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyNBk8Ru1Rour9O3qMb/h06B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamdanXI/nlp_adventure/blob/main/802%20code/bleurt-evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nok_cQ80o4B6"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets tqdm\n",
        "!pip install git+https://github.com/google-research/bleurt.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from datasets import load_dataset\n",
        "from datasets import load_metric\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "bleurt_metric = load_metric('bleurt')\n",
        "\n",
        "t5_small_paradetox_1Token_tokenizer = AutoTokenizer.from_pretrained(\"HamdanXI/t5-small-paradetox-1Token-split-masked\")\n",
        "t5_small_paradetox_1Token_model = AutoModelForSeq2SeqLM.from_pretrained(\"HamdanXI/t5-small-paradetox-1Token-split-masked\")\n",
        "\n",
        "# BART-base-detox (10,000 epochs with the learning rate of 3e-5)\n",
        "bart_base_detox_tokenizer = AutoTokenizer.from_pretrained(\"s-nlp/bart-base-detox\")\n",
        "bart_base_detox_model = AutoModelForSeq2SeqLM.from_pretrained(\"s-nlp/bart-base-detox\")\n",
        "\n",
        "bart_base_paradetox_split_tokenizer = AutoTokenizer.from_pretrained(\"HamdanXI/bart-base-paradetox-split\")\n",
        "bart_base_paradetox_split_model = AutoModelForSeq2SeqLM.from_pretrained(\"HamdanXI/bart-base-paradetox-split\")\n",
        "\n",
        "\n",
        "paradetox_dataset = load_dataset(\"HamdanXI/paradetox-split\")\n",
        "paradetox_1token_dataset = load_dataset(\"HamdanXI/paradetox-1Token-Split\")"
      ],
      "metadata": {
        "id": "dzGIO-zHo6CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def max_token_length(input, label, tokenizer):\n",
        "  max_token_length_input = max(len(tokenizer.encode(item)) for item in input)\n",
        "  max_token_length_label = max(len(tokenizer.encode(item)) for item in label)\n",
        "\n",
        "  if max_token_length_input > max_token_length_label:\n",
        "      highest_length = max_token_length_input\n",
        "  else:\n",
        "      highest_length = max_token_length_label\n",
        "\n",
        "  return highest_length"
      ],
      "metadata": {
        "id": "Fbi7BHa0ueDX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_predictions(texts, model, tokenizer, highest_length):\n",
        "    predictions = []\n",
        "    for text in tqdm(texts, desc=\"Generating predictions\"):\n",
        "        inputs = tokenizer(text, padding=True, truncation=True, max_length=highest_length, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(**inputs)\n",
        "        predictions.extend([tokenizer.decode(output, skip_special_tokens=True) for output in outputs])\n",
        "    return predictions\n",
        "\n",
        "def bleurt_evaluate(input, label, model, tokenizer, highest_length):\n",
        "    predictions = generate_predictions(input, model, tokenizer, highest_length)\n",
        "\n",
        "    score_results = bleurt_metric.compute(predictions=predictions, references=label)\n",
        "\n",
        "    scores = score_results['scores']\n",
        "\n",
        "    average_score = sum(scores) / len(scores) if scores else 0\n",
        "    print(f\"Average BLEURT Score: {average_score}\")"
      ],
      "metadata": {
        "id": "Hn48JdZ9ubPm"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "highest_length_1token_t5_small = max_token_length(paradetox_1token_dataset['test'][\"en_toxic_comment\"], paradetox_1token_dataset['test'][\"en_neutral_comment\"], t5_small_paradetox_1Token_tokenizer)\n",
        "highest_length_1token_bart_base = max_token_length(paradetox_1token_dataset['test'][\"en_toxic_comment\"], paradetox_1token_dataset['test'][\"en_neutral_comment\"], bart_base_detox_tokenizer)\n",
        "highest_length_1token_bart_base_split = max_token_length(paradetox_1token_dataset['test'][\"en_toxic_comment\"], paradetox_1token_dataset['test'][\"en_neutral_comment\"], bart_base_paradetox_split_tokenizer)"
      ],
      "metadata": {
        "id": "i0OeTjuKi7_q"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleurt_evaluate(paradetox_1token_dataset['test'][\"en_toxic_comment\"], paradetox_1token_dataset['test'][\"en_neutral_comment\"], t5_small_paradetox_1Token_model, t5_small_paradetox_1Token_tokenizer, highest_length_1token_t5_small)"
      ],
      "metadata": {
        "id": "QAzBrwSUpwnu",
        "outputId": "f2f0d2f1-3ee5-4b58-e9a9-0884b9870500",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEURT Score: 0.574729475563647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleurt_evaluate(paradetox_1token_dataset['test'][\"en_toxic_comment\"], paradetox_1token_dataset['test'][\"en_neutral_comment\"], bart_base_detox_model, bart_base_detox_tokenizer, highest_length_1token_bart_base)"
      ],
      "metadata": {
        "id": "assTLwCNkNMk",
        "outputId": "ed1ea69c-580f-4322-f8b0-4cbe257998e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating predictions:   0%|          | 0/811 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Generating predictions: 100%|██████████| 811/811 [05:25<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEURT Score: 0.6970971491275086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleurt_evaluate(paradetox_1token_dataset['test'][\"en_toxic_comment\"], paradetox_1token_dataset['test'][\"en_neutral_comment\"], bart_base_paradetox_split_model, bart_base_paradetox_split_tokenizer, highest_length_1token_bart_base_split)"
      ],
      "metadata": {
        "id": "k2xBSMhIKAEX",
        "outputId": "4f1a07dc-1dd8-4c6e-ab61-5160aa08fbf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating predictions: 100%|██████████| 811/811 [05:32<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEURT Score: 0.6858602125707522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "highest_length_t5_small = max_token_length(paradetox_dataset['test'][\"en_toxic_comment\"], paradetox_dataset['test'][\"en_neutral_comment\"], t5_small_paradetox_1Token_tokenizer)\n",
        "highest_length_bart_base = max_token_length(paradetox_dataset['test'][\"en_toxic_comment\"], paradetox_dataset['test'][\"en_neutral_comment\"], bart_base_detox_tokenizer)\n",
        "highest_length_bart_base_split = max_token_length(paradetox_dataset['test'][\"en_toxic_comment\"], paradetox_dataset['test'][\"en_neutral_comment\"], bart_base_paradetox_split_tokenizer)"
      ],
      "metadata": {
        "id": "1Zeeh8Q2ok23"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleurt_evaluate(paradetox_dataset['test'][\"en_toxic_comment\"], paradetox_dataset['test'][\"en_neutral_comment\"], t5_small_paradetox_1Token_model, t5_small_paradetox_1Token_tokenizer, highest_length_t5_small)"
      ],
      "metadata": {
        "id": "iTTSLbflopRj",
        "outputId": "73a7a285-2697-4925-cfa5-ccef77be653f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating predictions: 100%|██████████| 671/671 [02:21<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEURT Score: -0.44180790879021103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleurt_evaluate(paradetox_dataset['test'][\"en_toxic_comment\"], paradetox_dataset['test'][\"en_neutral_comment\"], bart_base_detox_model, bart_base_detox_tokenizer, highest_length_bart_base)"
      ],
      "metadata": {
        "id": "ZJURyPF7M3XF",
        "outputId": "e3fc330d-2979-46b9-d936-a654e8231031",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating predictions: 100%|██████████| 671/671 [04:28<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEURT Score: 0.2883815431992361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleurt_evaluate(paradetox_dataset['test'][\"en_toxic_comment\"], paradetox_dataset['test'][\"en_neutral_comment\"], bart_base_paradetox_split_model, bart_base_paradetox_split_tokenizer, highest_length_bart_base_split)"
      ],
      "metadata": {
        "id": "ETP9V1pYKejO",
        "outputId": "df0bebb9-e26c-46b1-a2bc-231c0b604fb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating predictions: 100%|██████████| 671/671 [05:00<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEURT Score: -0.13517926543418057\n"
          ]
        }
      ]
    }
  ]
}