As of my last update in January 2022, I'm not aware of specific models or techniques named "BLOOMZ" or "MT0" in the context of multilingual generalization. It's possible that these are new developments or models that have been introduced after 2022.

However, I can provide a general overview of multilingual generalization in the context of language models and its significance.

### Multilingual Generalization:

Multilingual generalization refers to a model's ability to perform tasks across multiple languages, especially when it's trained in a manner that involves multiple languages simultaneously. Models with multilingual capabilities can understand, generate, and switch between different languages, even if some of those languages had limited representation during training.

The motivation behind training multilingual models includes:

1. **Resource Efficiency**: A single multilingual model can handle tasks in many languages instead of maintaining a separate model for each language.
2. **Low-Resource Languages**: Multilingual models can generalize and perform reasonably well for languages with limited training data by leveraging knowledge from high-resource languages.
3. **Cross-Lingual Transfer**: In some cases, training on multiple languages can lead to improved performance in individual languages, especially for closely related languages.

### Examples:

1. **mBERT (Multilingual BERT)**:
   mBERT is a variant of the BERT model trained on text from multiple languages. It's designed to handle tasks in various languages without needing language-specific models. For instance, if you input a sentence in French to mBERT and ask for sentiment analysis, it can process it even if it was primarily trained on English sentiment data.

2. **Zero-Shot Translation**:
   Suppose a model is trained on English-to-French and English-to-German translations. With multilingual generalization, it might be able to perform French-to-German translations even if it has never seen direct translation data between these two languages.

3. **Language Identification**:
   A multilingual model can be prompted to identify the language of a given text. For instance, given the text "Hola, ¿cómo estás?", the model could identify it as Spanish.

If "BLOOMZ" and "MT0" refer to specific models or techniques developed after 2022, I recommend checking more recent literature or documentation related to these terms for detailed information.