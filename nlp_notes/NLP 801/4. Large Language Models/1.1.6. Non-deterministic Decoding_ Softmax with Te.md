Certainly!

**Non-deterministic Decoding: Softmax with Temperature**:

Softmax with temperature is a method to control the randomness in sequence generation by modifying the probability distribution over the tokens before sampling. The temperature is a scalar value used to scale the logits (pre-softmax values) produced by the model. Adjusting the temperature modifies the sharpness of the probability distribution.

The softmax function, used to convert logits to probabilities, is defined as:
$\text{Softmax}(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}}$
where $z$ is a vector of logits.

When introducing temperature \( T \), the formula becomes:
$\text{Softmax}(z_i) = \frac{e^{z_i/T}}{\sum_j e^{z_j/T}}$

**Effects of Temperature**:
- **T = 1**: No effect; the original probabilities from the model are used.
- **T > 1**: Makes the probability distribution "flatter". This increases randomness as the differences between probabilities of tokens become smaller.
- **T < 1**: Makes the probability distribution "sharper". This reduces randomness, making the model more likely to pick the most probable token.

**Example**:

Imagine you're using a language model to predict the next word in the sentence:

"Chocolate is ___."

Given this input, the model produces the following probabilities (simplified for the example):

- delicious: 0.7
- bad: 0.1
- available: 0.2

Using softmax with different temperatures:

1. **T = 2** (Increased randomness):
   - delicious: ~0.5
   - bad: ~0.2
   - available: ~0.3

   The probabilities are now closer to each other, and while "delicious" is still the most likely choice, there's a much higher chance than before to select "bad" or "available".

2. **T = 0.5** (Decreased randomness):
   - delicious: ~0.9
   - bad: ~0.05
   - available: ~0.05

   The probability distribution is sharper, making "delicious" even more likely to be chosen and the other options less likely.

By using softmax with temperature, you can control the trade-off between diversity and accuracy in the generated sequences. A higher temperature may lead to more varied and creative outputs, but they might be less coherent or accurate. Conversely, a lower temperature will produce more deterministic and accurate outputs, but they might be less diverse or more predictable.