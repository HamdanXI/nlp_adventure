{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNoqv1HE1/HyM1ll41osx4H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamdanXI/nlp_adventure/blob/main/ml801/evaluation_all_in_one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nok_cQ80o4B6"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets tqdm bert-score evaluate unbabel-comet\n",
        "!pip install git+https://github.com/google-research/bleurt.git\n",
        "!pip3 install git+https://github.com/Unbabel/COMET.git\n",
        "!pip install tensorflow --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from datasets import load_dataset\n",
        "from datasets import load_metric\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from evaluate import load\n",
        "\n",
        "bleurt_metric = load_metric('bleurt')\n",
        "comet_metric = load('comet')\n",
        "\n",
        "# Models\n",
        "cosine_tokenizer = AutoTokenizer.from_pretrained(\"HamdanXI/marefa-mt-en-ar-parallel-10k-splitted-cosine\")\n",
        "cosine_model = AutoModelForSeq2SeqLM.from_pretrained(\"HamdanXI/marefa-mt-en-ar-parallel-10k-splitted-cosine\")\n",
        "\n",
        "euclidean_tokenizer = AutoTokenizer.from_pretrained(\"HamdanXI/marefa-mt-en-ar-parallel-10k-splitted-euclidean\")\n",
        "euclidean_model = AutoModelForSeq2SeqLM.from_pretrained(\"HamdanXI/marefa-mt-en-ar-parallel-10k-splitted-euclidean\")\n",
        "\n",
        "translate_cosine_tokenizer = AutoTokenizer.from_pretrained(\"HamdanXI/marefa-mt-en-ar-parallel-10k-splitted-translated-cosine\")\n",
        "translate_cosine_model = AutoModelForSeq2SeqLM.from_pretrained(\"HamdanXI/marefa-mt-en-ar-parallel-10k-splitted-translated-cosine\")\n",
        "\n",
        "# Dataset\n",
        "dataset = load_dataset(\"HamdanXI/arb-eng-parallel-10k-splitted\", split=\"test\")"
      ],
      "metadata": {
        "id": "dzGIO-zHo6CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Max Token Length\n",
        "def max_token_length(input, label, tokenizer):\n",
        "  max_token_length_input = max(len(tokenizer.encode(item)) for item in input)\n",
        "  max_token_length_label = max(len(tokenizer.encode(item)) for item in label)\n",
        "\n",
        "  if max_token_length_input > max_token_length_label:\n",
        "      highest_length = max_token_length_input\n",
        "  else:\n",
        "      highest_length = max_token_length_label\n",
        "\n",
        "  return highest_length\n",
        "\n",
        "# Generate Predictions\n",
        "def generate_predictions(texts, model, tokenizer, highest_length):\n",
        "    predictions = []\n",
        "    for text in tqdm(texts, desc=\"Generating predictions\"):\n",
        "        inputs = tokenizer(text, padding=True, truncation=True, max_length=highest_length, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(**inputs)\n",
        "        predictions.extend([tokenizer.decode(output, skip_special_tokens=True) for output in outputs])\n",
        "    return predictions\n",
        "\n",
        "# BLEURT Evaluation\n",
        "def bleurt_evaluate(input, label, model, tokenizer, highest_length):\n",
        "    predictions = generate_predictions(input, model, tokenizer, highest_length)\n",
        "    score_results = bleurt_metric.compute(predictions=predictions, references=label)\n",
        "    scores = score_results['scores']\n",
        "    average_score = sum(scores) / len(scores) if scores else 0\n",
        "    print(f\"Average BLEURT Score: {average_score}\")\n",
        "\n",
        "# BERT Score Evaluation\n",
        "def bert_score_evaluate(input, label, model, tokenizer, highest_length):\n",
        "  predictions = generate_predictions(input, model, tokenizer, highest_length)\n",
        "  P, R, F1 = score(predictions, label, lang=\"en\", rescale_with_baseline=True)\n",
        "  print(f\"Precision: {P.mean()}, Recall: {R.mean()}, F1 Score: {F1.mean()}\")\n",
        "\n",
        "# COMET Evaluate\n",
        "def comet_evaluate(input, label, model, tokenizer, highest_length):\n",
        "    predictions = generate_predictions(input, model, tokenizer, highest_length)\n",
        "    comet_score = comet_metric.compute(predictions=predictions, references=label, sources=input)\n",
        "    print(comet_score)"
      ],
      "metadata": {
        "id": "Fbi7BHa0ueDX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to count the number of rows with token length greater than 512\n",
        "max_length=512\n",
        "\n",
        "def count_exceeding_token_length(inputs, labels, tokenizer, max_length=512):\n",
        "    count = 0\n",
        "    for input, label in zip(inputs, labels):\n",
        "        input_length = len(tokenizer.encode(input, add_special_tokens=True))\n",
        "        label_length = len(tokenizer.encode(label, add_special_tokens=True))\n",
        "        if input_length > max_length or label_length > max_length:\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "# Example usage\n",
        "exceeding_count = count_exceeding_token_length(dataset[\"english\"], dataset[\"arabic\"], cosine_tokenizer)\n",
        "print(f\"Number of rows exceeding the token length of {max_length}: {exceeding_count}\")"
      ],
      "metadata": {
        "id": "kobshWYqmyen",
        "outputId": "7e451d07-e68e-4d12-c90e-9223e0a60162",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows exceeding the token length of 512: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to filter out rows with token length greater than 512\n",
        "def filter_exceeding_token_length(inputs, labels, tokenizer, max_length=512):\n",
        "    filtered_inputs = []\n",
        "    filtered_labels = []\n",
        "    for input, label in zip(inputs, labels):\n",
        "        input_length = len(tokenizer.encode(input, add_special_tokens=True))\n",
        "        label_length = len(tokenizer.encode(label, add_special_tokens=True))\n",
        "        if input_length <= max_length and label_length <= max_length:\n",
        "            filtered_inputs.append(input)\n",
        "            filtered_labels.append(label)\n",
        "    return filtered_inputs, filtered_labels\n",
        "\n",
        "# Example usage\n",
        "filtered_english, filtered_arabic = filter_exceeding_token_length(dataset[\"english\"], dataset[\"arabic\"], cosine_tokenizer)\n",
        "\n",
        "filtered_data = {\n",
        "    \"english\": filtered_english,\n",
        "    \"arabic\": filtered_arabic\n",
        "}\n",
        "\n",
        "filtered_dataset = Dataset.from_dict(filtered_data)"
      ],
      "metadata": {
        "id": "OqS2bksynF1e"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "highest_length_cosine = max_token_length(filtered_dataset[\"english\"], filtered_dataset[\"arabic\"], cosine_tokenizer)\n",
        "highest_length_euclidean = max_token_length(filtered_dataset[\"english\"], filtered_dataset[\"arabic\"], euclidean_tokenizer)\n",
        "highest_length_translate_cosine = max_token_length(filtered_dataset[\"english\"], filtered_dataset[\"arabic\"], translate_cosine_tokenizer)"
      ],
      "metadata": {
        "id": "i0OeTjuKi7_q"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "0mcSp4E5ieLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine\n",
        "bleurt_evaluate(filtered_dataset[\"english\"], filtered_dataset[\"arabic\"], cosine_model, cosine_tokenizer, highest_length_cosine)\n",
        "# bert_score_evaluate(filtered_dataset[\"english\"], filtered_dataset[\"arabic\"], cosine_model, cosine_tokenizer, highest_length_cosine)\n",
        "# comet_evaluate(filtered_dataset[\"english\"], filtered_dataset[\"arabic\"], cosine_model, cosine_tokenizer, highest_length_cosine)"
      ],
      "metadata": {
        "id": "QAzBrwSUpwnu",
        "outputId": "b6fda9a2-f356-47a9-e3c7-7c6966d30210",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating predictions:  44%|████▎     | 431/990 [18:49<29:54,  3.21s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_score_evaluate(filtered_dataset[\"english\"], filtered_dataset[\"arabic\"], cosine_model, cosine_tokenizer, highest_length_cosine)"
      ],
      "metadata": {
        "id": "ynJiXyZoopdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comet_evaluate(filtered_dataset[\"english\"], filtered_dataset[\"arabic\"], cosine_model, cosine_tokenizer, highest_length_cosine)"
      ],
      "metadata": {
        "id": "5KiUVFVdoqzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Euclidean\n",
        "bleurt_evaluate(filtered_dataset[\"english\"], filtered_dataset[\"arabic\"], euclidean_model, euclidean_tokenizer, highest_length_euclidean)\n",
        "bert_score_evaluate(filtered_dataset[\"english\"], filtered_dataset[\"arabic\"], euclidean_model, euclidean_tokenizer, highest_length_euclidean)\n",
        "comet_evaluate(filtered_dataset[\"english\"], filtered_dataset[\"arabic\"], euclidean_model, euclidean_tokenizer, highest_length_euclidean)"
      ],
      "metadata": {
        "id": "assTLwCNkNMk",
        "outputId": "ed1ea69c-580f-4322-f8b0-4cbe257998e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating predictions:   0%|          | 0/811 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Generating predictions: 100%|██████████| 811/811 [05:25<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEURT Score: 0.6970971491275086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Translated Cosine\n",
        "bleurt_evaluate(filtered_dataset[\"english\"], filtered_dataset[\"arabic\"], translate_cosine_model, translate_cosine_tokenizer, highest_length_translate_cosine)\n",
        "bert_score_evaluate(filtered_dataset[\"english\"], filtered_dataset[\"arabic\"], translate_cosine_model, translate_cosine_tokenizer, highest_length_translate_cosine)\n",
        "comet_evaluate(filtered_dataset[\"english\"], filtered_dataset[\"arabic\"], translate_cosine_model, translate_cosine_tokenizer, highest_length_translate_cosine)"
      ],
      "metadata": {
        "id": "k2xBSMhIKAEX",
        "outputId": "4f1a07dc-1dd8-4c6e-ab61-5160aa08fbf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating predictions: 100%|██████████| 811/811 [05:32<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEURT Score: 0.6858602125707522\n"
          ]
        }
      ]
    }
  ]
}