{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamdanXI/nlp_adventure/blob/main/803/v2-lstm-600epoch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GIMVS0MPB_c",
        "outputId": "717cfef7-3fac-45eb-a182-bf769fe865bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy pandas tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('MFCC_with_Output.csv')\n",
        "\n",
        "data['MFCC'] = data['MFCC'].apply(lambda x: np.array([float(num) for num in x.strip('[]').split(',')]))\n",
        "\n",
        "# Preparing the dataset\n",
        "X = np.array(data['MFCC'].tolist())\n",
        "y = data['Output'].values\n",
        "\n",
        "# Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_encoded = to_categorical(y)\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape input to be [samples, time steps, features]\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Building the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(1, X_train.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(y_encoded.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7W-owaVyPD5R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=600, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwEZI6ztQxBo",
        "outputId": "86a0af2e-b9d0-4a36-85e1-fb583f7c7ca2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "102/102 [==============================] - 21s 58ms/step - loss: 2.2064 - accuracy: 0.3530 - val_loss: 2.0364 - val_accuracy: 0.4034\n",
            "Epoch 2/600\n",
            "102/102 [==============================] - 2s 18ms/step - loss: 1.8263 - accuracy: 0.4060 - val_loss: 1.7273 - val_accuracy: 0.4047\n",
            "Epoch 3/600\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 1.6896 - accuracy: 0.4127 - val_loss: 1.6815 - val_accuracy: 0.4047\n",
            "Epoch 4/600\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 1.6671 - accuracy: 0.4183 - val_loss: 1.6643 - val_accuracy: 0.4047\n",
            "Epoch 5/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.6489 - accuracy: 0.4204 - val_loss: 1.6541 - val_accuracy: 0.3985\n",
            "Epoch 6/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.6366 - accuracy: 0.4272 - val_loss: 1.6472 - val_accuracy: 0.4010\n",
            "Epoch 7/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.6282 - accuracy: 0.4263 - val_loss: 1.6400 - val_accuracy: 0.4010\n",
            "Epoch 8/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.6158 - accuracy: 0.4260 - val_loss: 1.6363 - val_accuracy: 0.4022\n",
            "Epoch 9/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.6155 - accuracy: 0.4315 - val_loss: 1.6325 - val_accuracy: 0.3998\n",
            "Epoch 10/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.6020 - accuracy: 0.4254 - val_loss: 1.6303 - val_accuracy: 0.4010\n",
            "Epoch 11/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.6005 - accuracy: 0.4287 - val_loss: 1.6266 - val_accuracy: 0.4084\n",
            "Epoch 12/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.5959 - accuracy: 0.4352 - val_loss: 1.6248 - val_accuracy: 0.4059\n",
            "Epoch 13/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5883 - accuracy: 0.4312 - val_loss: 1.6222 - val_accuracy: 0.4034\n",
            "Epoch 14/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5779 - accuracy: 0.4371 - val_loss: 1.6200 - val_accuracy: 0.3961\n",
            "Epoch 15/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5925 - accuracy: 0.4300 - val_loss: 1.6162 - val_accuracy: 0.4071\n",
            "Epoch 16/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5795 - accuracy: 0.4355 - val_loss: 1.6155 - val_accuracy: 0.4071\n",
            "Epoch 17/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5709 - accuracy: 0.4398 - val_loss: 1.6124 - val_accuracy: 0.4096\n",
            "Epoch 18/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.5781 - accuracy: 0.4395 - val_loss: 1.6095 - val_accuracy: 0.4096\n",
            "Epoch 19/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.5618 - accuracy: 0.4457 - val_loss: 1.6067 - val_accuracy: 0.4084\n",
            "Epoch 20/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.5593 - accuracy: 0.4512 - val_loss: 1.6048 - val_accuracy: 0.4157\n",
            "Epoch 21/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.5476 - accuracy: 0.4411 - val_loss: 1.6063 - val_accuracy: 0.4133\n",
            "Epoch 22/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5682 - accuracy: 0.4395 - val_loss: 1.6031 - val_accuracy: 0.4157\n",
            "Epoch 23/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5549 - accuracy: 0.4515 - val_loss: 1.6035 - val_accuracy: 0.4157\n",
            "Epoch 24/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5587 - accuracy: 0.4469 - val_loss: 1.5999 - val_accuracy: 0.4157\n",
            "Epoch 25/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5565 - accuracy: 0.4398 - val_loss: 1.5974 - val_accuracy: 0.4121\n",
            "Epoch 26/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.5521 - accuracy: 0.4512 - val_loss: 1.5984 - val_accuracy: 0.4133\n",
            "Epoch 27/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5513 - accuracy: 0.4420 - val_loss: 1.5990 - val_accuracy: 0.4108\n",
            "Epoch 28/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5477 - accuracy: 0.4481 - val_loss: 1.5963 - val_accuracy: 0.4108\n",
            "Epoch 29/600\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 1.5508 - accuracy: 0.4497 - val_loss: 1.5934 - val_accuracy: 0.4108\n",
            "Epoch 30/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5455 - accuracy: 0.4524 - val_loss: 1.5938 - val_accuracy: 0.4145\n",
            "Epoch 31/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5456 - accuracy: 0.4543 - val_loss: 1.5930 - val_accuracy: 0.4121\n",
            "Epoch 32/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.5350 - accuracy: 0.4481 - val_loss: 1.5909 - val_accuracy: 0.4121\n",
            "Epoch 33/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5445 - accuracy: 0.4497 - val_loss: 1.5881 - val_accuracy: 0.4157\n",
            "Epoch 34/600\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 1.5418 - accuracy: 0.4451 - val_loss: 1.5875 - val_accuracy: 0.4121\n",
            "Epoch 35/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.5322 - accuracy: 0.4494 - val_loss: 1.5858 - val_accuracy: 0.4121\n",
            "Epoch 36/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.5322 - accuracy: 0.4521 - val_loss: 1.5845 - val_accuracy: 0.4133\n",
            "Epoch 37/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.5350 - accuracy: 0.4555 - val_loss: 1.5837 - val_accuracy: 0.4145\n",
            "Epoch 38/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.5306 - accuracy: 0.4460 - val_loss: 1.5831 - val_accuracy: 0.4182\n",
            "Epoch 39/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5262 - accuracy: 0.4540 - val_loss: 1.5845 - val_accuracy: 0.4170\n",
            "Epoch 40/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5243 - accuracy: 0.4528 - val_loss: 1.5813 - val_accuracy: 0.4194\n",
            "Epoch 41/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.5200 - accuracy: 0.4568 - val_loss: 1.5834 - val_accuracy: 0.4207\n",
            "Epoch 42/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5289 - accuracy: 0.4552 - val_loss: 1.5786 - val_accuracy: 0.4244\n",
            "Epoch 43/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5240 - accuracy: 0.4528 - val_loss: 1.5793 - val_accuracy: 0.4194\n",
            "Epoch 44/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5207 - accuracy: 0.4608 - val_loss: 1.5761 - val_accuracy: 0.4231\n",
            "Epoch 45/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5216 - accuracy: 0.4561 - val_loss: 1.5768 - val_accuracy: 0.4280\n",
            "Epoch 46/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5181 - accuracy: 0.4589 - val_loss: 1.5759 - val_accuracy: 0.4207\n",
            "Epoch 47/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5154 - accuracy: 0.4568 - val_loss: 1.5782 - val_accuracy: 0.4256\n",
            "Epoch 48/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5133 - accuracy: 0.4571 - val_loss: 1.5765 - val_accuracy: 0.4256\n",
            "Epoch 49/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5049 - accuracy: 0.4583 - val_loss: 1.5750 - val_accuracy: 0.4256\n",
            "Epoch 50/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5036 - accuracy: 0.4552 - val_loss: 1.5728 - val_accuracy: 0.4280\n",
            "Epoch 51/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.5057 - accuracy: 0.4571 - val_loss: 1.5729 - val_accuracy: 0.4305\n",
            "Epoch 52/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.5121 - accuracy: 0.4580 - val_loss: 1.5719 - val_accuracy: 0.4305\n",
            "Epoch 53/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.5022 - accuracy: 0.4574 - val_loss: 1.5695 - val_accuracy: 0.4305\n",
            "Epoch 54/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5024 - accuracy: 0.4638 - val_loss: 1.5701 - val_accuracy: 0.4305\n",
            "Epoch 55/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.5028 - accuracy: 0.4641 - val_loss: 1.5677 - val_accuracy: 0.4305\n",
            "Epoch 56/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5067 - accuracy: 0.4614 - val_loss: 1.5704 - val_accuracy: 0.4268\n",
            "Epoch 57/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5008 - accuracy: 0.4657 - val_loss: 1.5701 - val_accuracy: 0.4256\n",
            "Epoch 58/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4919 - accuracy: 0.4629 - val_loss: 1.5678 - val_accuracy: 0.4354\n",
            "Epoch 59/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.4875 - accuracy: 0.4595 - val_loss: 1.5690 - val_accuracy: 0.4379\n",
            "Epoch 60/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4981 - accuracy: 0.4571 - val_loss: 1.5645 - val_accuracy: 0.4354\n",
            "Epoch 61/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5038 - accuracy: 0.4580 - val_loss: 1.5635 - val_accuracy: 0.4477\n",
            "Epoch 62/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4880 - accuracy: 0.4721 - val_loss: 1.5611 - val_accuracy: 0.4440\n",
            "Epoch 63/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.5017 - accuracy: 0.4558 - val_loss: 1.5646 - val_accuracy: 0.4416\n",
            "Epoch 64/600\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 1.4998 - accuracy: 0.4626 - val_loss: 1.5649 - val_accuracy: 0.4391\n",
            "Epoch 65/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4917 - accuracy: 0.4694 - val_loss: 1.5629 - val_accuracy: 0.4428\n",
            "Epoch 66/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4913 - accuracy: 0.4601 - val_loss: 1.5627 - val_accuracy: 0.4342\n",
            "Epoch 67/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4887 - accuracy: 0.4586 - val_loss: 1.5620 - val_accuracy: 0.4403\n",
            "Epoch 68/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.4864 - accuracy: 0.4632 - val_loss: 1.5621 - val_accuracy: 0.4440\n",
            "Epoch 69/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.4891 - accuracy: 0.4620 - val_loss: 1.5614 - val_accuracy: 0.4453\n",
            "Epoch 70/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.4803 - accuracy: 0.4654 - val_loss: 1.5608 - val_accuracy: 0.4453\n",
            "Epoch 71/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4833 - accuracy: 0.4657 - val_loss: 1.5573 - val_accuracy: 0.4416\n",
            "Epoch 72/600\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 1.4769 - accuracy: 0.4706 - val_loss: 1.5608 - val_accuracy: 0.4465\n",
            "Epoch 73/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4856 - accuracy: 0.4648 - val_loss: 1.5589 - val_accuracy: 0.4465\n",
            "Epoch 74/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4846 - accuracy: 0.4706 - val_loss: 1.5588 - val_accuracy: 0.4477\n",
            "Epoch 75/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4859 - accuracy: 0.4645 - val_loss: 1.5607 - val_accuracy: 0.4440\n",
            "Epoch 76/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4791 - accuracy: 0.4651 - val_loss: 1.5581 - val_accuracy: 0.4465\n",
            "Epoch 77/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4727 - accuracy: 0.4749 - val_loss: 1.5630 - val_accuracy: 0.4490\n",
            "Epoch 78/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4832 - accuracy: 0.4657 - val_loss: 1.5580 - val_accuracy: 0.4477\n",
            "Epoch 79/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4742 - accuracy: 0.4660 - val_loss: 1.5571 - val_accuracy: 0.4490\n",
            "Epoch 80/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4611 - accuracy: 0.4666 - val_loss: 1.5596 - val_accuracy: 0.4502\n",
            "Epoch 81/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4718 - accuracy: 0.4700 - val_loss: 1.5597 - val_accuracy: 0.4502\n",
            "Epoch 82/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4762 - accuracy: 0.4672 - val_loss: 1.5599 - val_accuracy: 0.4477\n",
            "Epoch 83/600\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 1.4705 - accuracy: 0.4703 - val_loss: 1.5570 - val_accuracy: 0.4551\n",
            "Epoch 84/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.4805 - accuracy: 0.4678 - val_loss: 1.5567 - val_accuracy: 0.4514\n",
            "Epoch 85/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.4767 - accuracy: 0.4654 - val_loss: 1.5594 - val_accuracy: 0.4563\n",
            "Epoch 86/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.4621 - accuracy: 0.4734 - val_loss: 1.5617 - val_accuracy: 0.4600\n",
            "Epoch 87/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4662 - accuracy: 0.4672 - val_loss: 1.5568 - val_accuracy: 0.4588\n",
            "Epoch 88/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4613 - accuracy: 0.4715 - val_loss: 1.5559 - val_accuracy: 0.4600\n",
            "Epoch 89/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4660 - accuracy: 0.4678 - val_loss: 1.5555 - val_accuracy: 0.4588\n",
            "Epoch 90/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4639 - accuracy: 0.4718 - val_loss: 1.5534 - val_accuracy: 0.4539\n",
            "Epoch 91/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4664 - accuracy: 0.4740 - val_loss: 1.5530 - val_accuracy: 0.4588\n",
            "Epoch 92/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4590 - accuracy: 0.4685 - val_loss: 1.5532 - val_accuracy: 0.4526\n",
            "Epoch 93/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4694 - accuracy: 0.4737 - val_loss: 1.5543 - val_accuracy: 0.4539\n",
            "Epoch 94/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4579 - accuracy: 0.4731 - val_loss: 1.5574 - val_accuracy: 0.4539\n",
            "Epoch 95/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4554 - accuracy: 0.4789 - val_loss: 1.5550 - val_accuracy: 0.4576\n",
            "Epoch 96/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4519 - accuracy: 0.4706 - val_loss: 1.5550 - val_accuracy: 0.4526\n",
            "Epoch 97/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4557 - accuracy: 0.4660 - val_loss: 1.5523 - val_accuracy: 0.4551\n",
            "Epoch 98/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4600 - accuracy: 0.4709 - val_loss: 1.5560 - val_accuracy: 0.4477\n",
            "Epoch 99/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.4633 - accuracy: 0.4768 - val_loss: 1.5533 - val_accuracy: 0.4526\n",
            "Epoch 100/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.4638 - accuracy: 0.4688 - val_loss: 1.5525 - val_accuracy: 0.4502\n",
            "Epoch 101/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.4495 - accuracy: 0.4638 - val_loss: 1.5543 - val_accuracy: 0.4502\n",
            "Epoch 102/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.4551 - accuracy: 0.4795 - val_loss: 1.5525 - val_accuracy: 0.4502\n",
            "Epoch 103/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.4482 - accuracy: 0.4758 - val_loss: 1.5531 - val_accuracy: 0.4551\n",
            "Epoch 104/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4541 - accuracy: 0.4706 - val_loss: 1.5518 - val_accuracy: 0.4477\n",
            "Epoch 105/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4547 - accuracy: 0.4734 - val_loss: 1.5533 - val_accuracy: 0.4502\n",
            "Epoch 106/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.4513 - accuracy: 0.4798 - val_loss: 1.5533 - val_accuracy: 0.4502\n",
            "Epoch 107/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4465 - accuracy: 0.4734 - val_loss: 1.5489 - val_accuracy: 0.4490\n",
            "Epoch 108/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.4495 - accuracy: 0.4792 - val_loss: 1.5508 - val_accuracy: 0.4477\n",
            "Epoch 109/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4469 - accuracy: 0.4808 - val_loss: 1.5500 - val_accuracy: 0.4502\n",
            "Epoch 110/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4492 - accuracy: 0.4746 - val_loss: 1.5497 - val_accuracy: 0.4490\n",
            "Epoch 111/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4579 - accuracy: 0.4761 - val_loss: 1.5478 - val_accuracy: 0.4465\n",
            "Epoch 112/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4493 - accuracy: 0.4663 - val_loss: 1.5522 - val_accuracy: 0.4502\n",
            "Epoch 113/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4528 - accuracy: 0.4697 - val_loss: 1.5496 - val_accuracy: 0.4477\n",
            "Epoch 114/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4411 - accuracy: 0.4826 - val_loss: 1.5471 - val_accuracy: 0.4465\n",
            "Epoch 115/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4455 - accuracy: 0.4817 - val_loss: 1.5457 - val_accuracy: 0.4477\n",
            "Epoch 116/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.4353 - accuracy: 0.4801 - val_loss: 1.5467 - val_accuracy: 0.4477\n",
            "Epoch 117/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.4432 - accuracy: 0.4758 - val_loss: 1.5489 - val_accuracy: 0.4502\n",
            "Epoch 118/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.4391 - accuracy: 0.4851 - val_loss: 1.5518 - val_accuracy: 0.4465\n",
            "Epoch 119/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.4433 - accuracy: 0.4718 - val_loss: 1.5488 - val_accuracy: 0.4490\n",
            "Epoch 120/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.4445 - accuracy: 0.4743 - val_loss: 1.5470 - val_accuracy: 0.4477\n",
            "Epoch 121/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4405 - accuracy: 0.4774 - val_loss: 1.5486 - val_accuracy: 0.4490\n",
            "Epoch 122/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4275 - accuracy: 0.4869 - val_loss: 1.5473 - val_accuracy: 0.4502\n",
            "Epoch 123/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4386 - accuracy: 0.4823 - val_loss: 1.5477 - val_accuracy: 0.4465\n",
            "Epoch 124/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4213 - accuracy: 0.4765 - val_loss: 1.5480 - val_accuracy: 0.4477\n",
            "Epoch 125/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4360 - accuracy: 0.4817 - val_loss: 1.5458 - val_accuracy: 0.4502\n",
            "Epoch 126/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4440 - accuracy: 0.4755 - val_loss: 1.5473 - val_accuracy: 0.4514\n",
            "Epoch 127/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4300 - accuracy: 0.4848 - val_loss: 1.5467 - val_accuracy: 0.4551\n",
            "Epoch 128/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.4279 - accuracy: 0.4814 - val_loss: 1.5458 - val_accuracy: 0.4514\n",
            "Epoch 129/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4268 - accuracy: 0.4838 - val_loss: 1.5421 - val_accuracy: 0.4526\n",
            "Epoch 130/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4359 - accuracy: 0.4715 - val_loss: 1.5484 - val_accuracy: 0.4490\n",
            "Epoch 131/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.4358 - accuracy: 0.4835 - val_loss: 1.5442 - val_accuracy: 0.4551\n",
            "Epoch 132/600\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 1.4323 - accuracy: 0.4832 - val_loss: 1.5430 - val_accuracy: 0.4563\n",
            "Epoch 133/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.4361 - accuracy: 0.4755 - val_loss: 1.5469 - val_accuracy: 0.4563\n",
            "Epoch 134/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.4361 - accuracy: 0.4734 - val_loss: 1.5495 - val_accuracy: 0.4563\n",
            "Epoch 135/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4264 - accuracy: 0.4845 - val_loss: 1.5495 - val_accuracy: 0.4502\n",
            "Epoch 136/600\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 1.4340 - accuracy: 0.4817 - val_loss: 1.5497 - val_accuracy: 0.4477\n",
            "Epoch 137/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4236 - accuracy: 0.4795 - val_loss: 1.5486 - val_accuracy: 0.4514\n",
            "Epoch 138/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4256 - accuracy: 0.4820 - val_loss: 1.5468 - val_accuracy: 0.4526\n",
            "Epoch 139/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4339 - accuracy: 0.4780 - val_loss: 1.5468 - val_accuracy: 0.4539\n",
            "Epoch 140/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4195 - accuracy: 0.4851 - val_loss: 1.5500 - val_accuracy: 0.4477\n",
            "Epoch 141/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.4262 - accuracy: 0.4829 - val_loss: 1.5494 - val_accuracy: 0.4490\n",
            "Epoch 142/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4198 - accuracy: 0.4934 - val_loss: 1.5475 - val_accuracy: 0.4490\n",
            "Epoch 143/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.4244 - accuracy: 0.4783 - val_loss: 1.5455 - val_accuracy: 0.4526\n",
            "Epoch 144/600\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 1.4239 - accuracy: 0.4817 - val_loss: 1.5491 - val_accuracy: 0.4502\n",
            "Epoch 145/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4170 - accuracy: 0.4872 - val_loss: 1.5482 - val_accuracy: 0.4551\n",
            "Epoch 146/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4274 - accuracy: 0.4826 - val_loss: 1.5474 - val_accuracy: 0.4514\n",
            "Epoch 147/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.4196 - accuracy: 0.4835 - val_loss: 1.5484 - val_accuracy: 0.4490\n",
            "Epoch 148/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.4290 - accuracy: 0.4872 - val_loss: 1.5443 - val_accuracy: 0.4526\n",
            "Epoch 149/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.4070 - accuracy: 0.4857 - val_loss: 1.5470 - val_accuracy: 0.4502\n",
            "Epoch 150/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.4320 - accuracy: 0.4758 - val_loss: 1.5445 - val_accuracy: 0.4502\n",
            "Epoch 151/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4122 - accuracy: 0.4906 - val_loss: 1.5455 - val_accuracy: 0.4477\n",
            "Epoch 152/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.4110 - accuracy: 0.4906 - val_loss: 1.5470 - val_accuracy: 0.4490\n",
            "Epoch 153/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4215 - accuracy: 0.4814 - val_loss: 1.5465 - val_accuracy: 0.4465\n",
            "Epoch 154/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.4161 - accuracy: 0.4832 - val_loss: 1.5472 - val_accuracy: 0.4428\n",
            "Epoch 155/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4130 - accuracy: 0.4817 - val_loss: 1.5469 - val_accuracy: 0.4416\n",
            "Epoch 156/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4208 - accuracy: 0.4801 - val_loss: 1.5455 - val_accuracy: 0.4440\n",
            "Epoch 157/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4237 - accuracy: 0.4826 - val_loss: 1.5442 - val_accuracy: 0.4428\n",
            "Epoch 158/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4105 - accuracy: 0.4854 - val_loss: 1.5424 - val_accuracy: 0.4416\n",
            "Epoch 159/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4071 - accuracy: 0.4823 - val_loss: 1.5449 - val_accuracy: 0.4440\n",
            "Epoch 160/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4085 - accuracy: 0.4931 - val_loss: 1.5459 - val_accuracy: 0.4465\n",
            "Epoch 161/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4091 - accuracy: 0.4860 - val_loss: 1.5447 - val_accuracy: 0.4403\n",
            "Epoch 162/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4055 - accuracy: 0.4952 - val_loss: 1.5441 - val_accuracy: 0.4428\n",
            "Epoch 163/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.4162 - accuracy: 0.4823 - val_loss: 1.5449 - val_accuracy: 0.4440\n",
            "Epoch 164/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.4030 - accuracy: 0.4888 - val_loss: 1.5459 - val_accuracy: 0.4477\n",
            "Epoch 165/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.4055 - accuracy: 0.4885 - val_loss: 1.5486 - val_accuracy: 0.4453\n",
            "Epoch 166/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.4041 - accuracy: 0.4885 - val_loss: 1.5495 - val_accuracy: 0.4465\n",
            "Epoch 167/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4144 - accuracy: 0.4841 - val_loss: 1.5405 - val_accuracy: 0.4465\n",
            "Epoch 168/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4111 - accuracy: 0.4903 - val_loss: 1.5459 - val_accuracy: 0.4477\n",
            "Epoch 169/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4076 - accuracy: 0.4909 - val_loss: 1.5451 - val_accuracy: 0.4440\n",
            "Epoch 170/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.4154 - accuracy: 0.4872 - val_loss: 1.5426 - val_accuracy: 0.4453\n",
            "Epoch 171/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4098 - accuracy: 0.4882 - val_loss: 1.5468 - val_accuracy: 0.4453\n",
            "Epoch 172/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4157 - accuracy: 0.4792 - val_loss: 1.5452 - val_accuracy: 0.4490\n",
            "Epoch 173/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3975 - accuracy: 0.4928 - val_loss: 1.5474 - val_accuracy: 0.4367\n",
            "Epoch 174/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3947 - accuracy: 0.4949 - val_loss: 1.5447 - val_accuracy: 0.4477\n",
            "Epoch 175/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4108 - accuracy: 0.4912 - val_loss: 1.5456 - val_accuracy: 0.4477\n",
            "Epoch 176/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3989 - accuracy: 0.4971 - val_loss: 1.5474 - val_accuracy: 0.4440\n",
            "Epoch 177/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4070 - accuracy: 0.4851 - val_loss: 1.5486 - val_accuracy: 0.4379\n",
            "Epoch 178/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3998 - accuracy: 0.4845 - val_loss: 1.5512 - val_accuracy: 0.4440\n",
            "Epoch 179/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3863 - accuracy: 0.4872 - val_loss: 1.5495 - val_accuracy: 0.4465\n",
            "Epoch 180/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4053 - accuracy: 0.4928 - val_loss: 1.5471 - val_accuracy: 0.4391\n",
            "Epoch 181/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3968 - accuracy: 0.4894 - val_loss: 1.5443 - val_accuracy: 0.4403\n",
            "Epoch 182/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.4245 - accuracy: 0.4854 - val_loss: 1.5476 - val_accuracy: 0.4428\n",
            "Epoch 183/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.4007 - accuracy: 0.4875 - val_loss: 1.5473 - val_accuracy: 0.4391\n",
            "Epoch 184/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4055 - accuracy: 0.4934 - val_loss: 1.5472 - val_accuracy: 0.4367\n",
            "Epoch 185/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4024 - accuracy: 0.4955 - val_loss: 1.5480 - val_accuracy: 0.4403\n",
            "Epoch 186/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3956 - accuracy: 0.4869 - val_loss: 1.5469 - val_accuracy: 0.4403\n",
            "Epoch 187/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3988 - accuracy: 0.4805 - val_loss: 1.5488 - val_accuracy: 0.4477\n",
            "Epoch 188/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3959 - accuracy: 0.4952 - val_loss: 1.5474 - val_accuracy: 0.4403\n",
            "Epoch 189/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3959 - accuracy: 0.4829 - val_loss: 1.5511 - val_accuracy: 0.4403\n",
            "Epoch 190/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4017 - accuracy: 0.4878 - val_loss: 1.5457 - val_accuracy: 0.4379\n",
            "Epoch 191/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3900 - accuracy: 0.4888 - val_loss: 1.5447 - val_accuracy: 0.4440\n",
            "Epoch 192/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3872 - accuracy: 0.4952 - val_loss: 1.5425 - val_accuracy: 0.4440\n",
            "Epoch 193/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3943 - accuracy: 0.4906 - val_loss: 1.5474 - val_accuracy: 0.4391\n",
            "Epoch 194/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3995 - accuracy: 0.4875 - val_loss: 1.5495 - val_accuracy: 0.4416\n",
            "Epoch 195/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3934 - accuracy: 0.4878 - val_loss: 1.5502 - val_accuracy: 0.4403\n",
            "Epoch 196/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4012 - accuracy: 0.4863 - val_loss: 1.5460 - val_accuracy: 0.4477\n",
            "Epoch 197/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.4004 - accuracy: 0.4906 - val_loss: 1.5436 - val_accuracy: 0.4490\n",
            "Epoch 198/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3803 - accuracy: 0.5011 - val_loss: 1.5478 - val_accuracy: 0.4477\n",
            "Epoch 199/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3987 - accuracy: 0.4922 - val_loss: 1.5439 - val_accuracy: 0.4490\n",
            "Epoch 200/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.4029 - accuracy: 0.4823 - val_loss: 1.5436 - val_accuracy: 0.4453\n",
            "Epoch 201/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3929 - accuracy: 0.4937 - val_loss: 1.5424 - val_accuracy: 0.4453\n",
            "Epoch 202/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3901 - accuracy: 0.4829 - val_loss: 1.5447 - val_accuracy: 0.4465\n",
            "Epoch 203/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3929 - accuracy: 0.4922 - val_loss: 1.5480 - val_accuracy: 0.4465\n",
            "Epoch 204/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3878 - accuracy: 0.4931 - val_loss: 1.5450 - val_accuracy: 0.4514\n",
            "Epoch 205/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3854 - accuracy: 0.4922 - val_loss: 1.5488 - val_accuracy: 0.4453\n",
            "Epoch 206/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3899 - accuracy: 0.4986 - val_loss: 1.5500 - val_accuracy: 0.4403\n",
            "Epoch 207/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.4033 - accuracy: 0.4857 - val_loss: 1.5479 - val_accuracy: 0.4465\n",
            "Epoch 208/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3906 - accuracy: 0.4894 - val_loss: 1.5540 - val_accuracy: 0.4440\n",
            "Epoch 209/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3798 - accuracy: 0.4995 - val_loss: 1.5488 - val_accuracy: 0.4428\n",
            "Epoch 210/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3807 - accuracy: 0.4891 - val_loss: 1.5536 - val_accuracy: 0.4465\n",
            "Epoch 211/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3772 - accuracy: 0.5042 - val_loss: 1.5488 - val_accuracy: 0.4403\n",
            "Epoch 212/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3825 - accuracy: 0.4909 - val_loss: 1.5461 - val_accuracy: 0.4453\n",
            "Epoch 213/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3802 - accuracy: 0.4980 - val_loss: 1.5470 - val_accuracy: 0.4453\n",
            "Epoch 214/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3850 - accuracy: 0.4971 - val_loss: 1.5488 - val_accuracy: 0.4453\n",
            "Epoch 215/600\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 1.3808 - accuracy: 0.4958 - val_loss: 1.5495 - val_accuracy: 0.4440\n",
            "Epoch 216/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3930 - accuracy: 0.4922 - val_loss: 1.5458 - val_accuracy: 0.4416\n",
            "Epoch 217/600\n",
            "102/102 [==============================] - 1s 13ms/step - loss: 1.3898 - accuracy: 0.4928 - val_loss: 1.5478 - val_accuracy: 0.4453\n",
            "Epoch 218/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3683 - accuracy: 0.5125 - val_loss: 1.5532 - val_accuracy: 0.4440\n",
            "Epoch 219/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3866 - accuracy: 0.4977 - val_loss: 1.5518 - val_accuracy: 0.4440\n",
            "Epoch 220/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3808 - accuracy: 0.4998 - val_loss: 1.5476 - val_accuracy: 0.4428\n",
            "Epoch 221/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3731 - accuracy: 0.4983 - val_loss: 1.5514 - val_accuracy: 0.4428\n",
            "Epoch 222/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3860 - accuracy: 0.4906 - val_loss: 1.5477 - val_accuracy: 0.4502\n",
            "Epoch 223/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3784 - accuracy: 0.4897 - val_loss: 1.5528 - val_accuracy: 0.4440\n",
            "Epoch 224/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3788 - accuracy: 0.4891 - val_loss: 1.5588 - val_accuracy: 0.4440\n",
            "Epoch 225/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3837 - accuracy: 0.4995 - val_loss: 1.5525 - val_accuracy: 0.4379\n",
            "Epoch 226/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3713 - accuracy: 0.4949 - val_loss: 1.5513 - val_accuracy: 0.4403\n",
            "Epoch 227/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3739 - accuracy: 0.5011 - val_loss: 1.5517 - val_accuracy: 0.4440\n",
            "Epoch 228/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3740 - accuracy: 0.5020 - val_loss: 1.5542 - val_accuracy: 0.4440\n",
            "Epoch 229/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3752 - accuracy: 0.4934 - val_loss: 1.5537 - val_accuracy: 0.4428\n",
            "Epoch 230/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3884 - accuracy: 0.4977 - val_loss: 1.5506 - val_accuracy: 0.4403\n",
            "Epoch 231/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3821 - accuracy: 0.4983 - val_loss: 1.5483 - val_accuracy: 0.4416\n",
            "Epoch 232/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3723 - accuracy: 0.4965 - val_loss: 1.5513 - val_accuracy: 0.4465\n",
            "Epoch 233/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3632 - accuracy: 0.4983 - val_loss: 1.5501 - val_accuracy: 0.4379\n",
            "Epoch 234/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3755 - accuracy: 0.4940 - val_loss: 1.5518 - val_accuracy: 0.4391\n",
            "Epoch 235/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3686 - accuracy: 0.5008 - val_loss: 1.5522 - val_accuracy: 0.4391\n",
            "Epoch 236/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3819 - accuracy: 0.4922 - val_loss: 1.5545 - val_accuracy: 0.4354\n",
            "Epoch 237/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3833 - accuracy: 0.4980 - val_loss: 1.5513 - val_accuracy: 0.4428\n",
            "Epoch 238/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3744 - accuracy: 0.4934 - val_loss: 1.5483 - val_accuracy: 0.4428\n",
            "Epoch 239/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3828 - accuracy: 0.4965 - val_loss: 1.5534 - val_accuracy: 0.4490\n",
            "Epoch 240/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3750 - accuracy: 0.4980 - val_loss: 1.5487 - val_accuracy: 0.4367\n",
            "Epoch 241/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3594 - accuracy: 0.5045 - val_loss: 1.5555 - val_accuracy: 0.4391\n",
            "Epoch 242/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3590 - accuracy: 0.4983 - val_loss: 1.5552 - val_accuracy: 0.4453\n",
            "Epoch 243/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3615 - accuracy: 0.5008 - val_loss: 1.5572 - val_accuracy: 0.4391\n",
            "Epoch 244/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3745 - accuracy: 0.5005 - val_loss: 1.5554 - val_accuracy: 0.4416\n",
            "Epoch 245/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3722 - accuracy: 0.4968 - val_loss: 1.5544 - val_accuracy: 0.4403\n",
            "Epoch 246/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3830 - accuracy: 0.4915 - val_loss: 1.5521 - val_accuracy: 0.4453\n",
            "Epoch 247/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3599 - accuracy: 0.4998 - val_loss: 1.5544 - val_accuracy: 0.4416\n",
            "Epoch 248/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3860 - accuracy: 0.4909 - val_loss: 1.5510 - val_accuracy: 0.4416\n",
            "Epoch 249/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3704 - accuracy: 0.4872 - val_loss: 1.5521 - val_accuracy: 0.4453\n",
            "Epoch 250/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3772 - accuracy: 0.4937 - val_loss: 1.5492 - val_accuracy: 0.4428\n",
            "Epoch 251/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3803 - accuracy: 0.4928 - val_loss: 1.5489 - val_accuracy: 0.4453\n",
            "Epoch 252/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3758 - accuracy: 0.4998 - val_loss: 1.5559 - val_accuracy: 0.4453\n",
            "Epoch 253/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3750 - accuracy: 0.4986 - val_loss: 1.5567 - val_accuracy: 0.4416\n",
            "Epoch 254/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3618 - accuracy: 0.5029 - val_loss: 1.5603 - val_accuracy: 0.4379\n",
            "Epoch 255/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3607 - accuracy: 0.5112 - val_loss: 1.5588 - val_accuracy: 0.4354\n",
            "Epoch 256/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3668 - accuracy: 0.4983 - val_loss: 1.5607 - val_accuracy: 0.4367\n",
            "Epoch 257/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3655 - accuracy: 0.5085 - val_loss: 1.5582 - val_accuracy: 0.4354\n",
            "Epoch 258/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3681 - accuracy: 0.4995 - val_loss: 1.5574 - val_accuracy: 0.4428\n",
            "Epoch 259/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3726 - accuracy: 0.4891 - val_loss: 1.5559 - val_accuracy: 0.4428\n",
            "Epoch 260/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3642 - accuracy: 0.5054 - val_loss: 1.5596 - val_accuracy: 0.4428\n",
            "Epoch 261/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3737 - accuracy: 0.5038 - val_loss: 1.5637 - val_accuracy: 0.4379\n",
            "Epoch 262/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3695 - accuracy: 0.5014 - val_loss: 1.5596 - val_accuracy: 0.4342\n",
            "Epoch 263/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3587 - accuracy: 0.4949 - val_loss: 1.5551 - val_accuracy: 0.4403\n",
            "Epoch 264/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3714 - accuracy: 0.5023 - val_loss: 1.5563 - val_accuracy: 0.4416\n",
            "Epoch 265/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3453 - accuracy: 0.5072 - val_loss: 1.5621 - val_accuracy: 0.4391\n",
            "Epoch 266/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3607 - accuracy: 0.5002 - val_loss: 1.5615 - val_accuracy: 0.4428\n",
            "Epoch 267/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3426 - accuracy: 0.5109 - val_loss: 1.5617 - val_accuracy: 0.4354\n",
            "Epoch 268/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3624 - accuracy: 0.5137 - val_loss: 1.5576 - val_accuracy: 0.4354\n",
            "Epoch 269/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3676 - accuracy: 0.5048 - val_loss: 1.5606 - val_accuracy: 0.4403\n",
            "Epoch 270/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3468 - accuracy: 0.5091 - val_loss: 1.5624 - val_accuracy: 0.4379\n",
            "Epoch 271/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3485 - accuracy: 0.5011 - val_loss: 1.5609 - val_accuracy: 0.4440\n",
            "Epoch 272/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3592 - accuracy: 0.5118 - val_loss: 1.5582 - val_accuracy: 0.4453\n",
            "Epoch 273/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3586 - accuracy: 0.5035 - val_loss: 1.5606 - val_accuracy: 0.4416\n",
            "Epoch 274/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3455 - accuracy: 0.5072 - val_loss: 1.5627 - val_accuracy: 0.4403\n",
            "Epoch 275/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3408 - accuracy: 0.5100 - val_loss: 1.5653 - val_accuracy: 0.4367\n",
            "Epoch 276/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3641 - accuracy: 0.5066 - val_loss: 1.5599 - val_accuracy: 0.4330\n",
            "Epoch 277/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3561 - accuracy: 0.5014 - val_loss: 1.5564 - val_accuracy: 0.4379\n",
            "Epoch 278/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3449 - accuracy: 0.5057 - val_loss: 1.5566 - val_accuracy: 0.4403\n",
            "Epoch 279/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3573 - accuracy: 0.5057 - val_loss: 1.5568 - val_accuracy: 0.4403\n",
            "Epoch 280/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3456 - accuracy: 0.5085 - val_loss: 1.5619 - val_accuracy: 0.4367\n",
            "Epoch 281/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3609 - accuracy: 0.5026 - val_loss: 1.5594 - val_accuracy: 0.4342\n",
            "Epoch 282/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3532 - accuracy: 0.5020 - val_loss: 1.5583 - val_accuracy: 0.4330\n",
            "Epoch 283/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3511 - accuracy: 0.5023 - val_loss: 1.5568 - val_accuracy: 0.4342\n",
            "Epoch 284/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3626 - accuracy: 0.5072 - val_loss: 1.5583 - val_accuracy: 0.4354\n",
            "Epoch 285/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3644 - accuracy: 0.4974 - val_loss: 1.5568 - val_accuracy: 0.4416\n",
            "Epoch 286/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3344 - accuracy: 0.5229 - val_loss: 1.5624 - val_accuracy: 0.4354\n",
            "Epoch 287/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3521 - accuracy: 0.5014 - val_loss: 1.5600 - val_accuracy: 0.4342\n",
            "Epoch 288/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3598 - accuracy: 0.5088 - val_loss: 1.5630 - val_accuracy: 0.4416\n",
            "Epoch 289/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3480 - accuracy: 0.5023 - val_loss: 1.5610 - val_accuracy: 0.4379\n",
            "Epoch 290/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3406 - accuracy: 0.5097 - val_loss: 1.5620 - val_accuracy: 0.4428\n",
            "Epoch 291/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3636 - accuracy: 0.4998 - val_loss: 1.5597 - val_accuracy: 0.4440\n",
            "Epoch 292/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3530 - accuracy: 0.4900 - val_loss: 1.5570 - val_accuracy: 0.4403\n",
            "Epoch 293/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3595 - accuracy: 0.5038 - val_loss: 1.5572 - val_accuracy: 0.4416\n",
            "Epoch 294/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3428 - accuracy: 0.5072 - val_loss: 1.5642 - val_accuracy: 0.4391\n",
            "Epoch 295/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3564 - accuracy: 0.4962 - val_loss: 1.5602 - val_accuracy: 0.4367\n",
            "Epoch 296/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3591 - accuracy: 0.5060 - val_loss: 1.5601 - val_accuracy: 0.4428\n",
            "Epoch 297/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3470 - accuracy: 0.5008 - val_loss: 1.5591 - val_accuracy: 0.4391\n",
            "Epoch 298/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3676 - accuracy: 0.4995 - val_loss: 1.5612 - val_accuracy: 0.4428\n",
            "Epoch 299/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3568 - accuracy: 0.5026 - val_loss: 1.5622 - val_accuracy: 0.4391\n",
            "Epoch 300/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3463 - accuracy: 0.5008 - val_loss: 1.5604 - val_accuracy: 0.4416\n",
            "Epoch 301/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3456 - accuracy: 0.5100 - val_loss: 1.5633 - val_accuracy: 0.4453\n",
            "Epoch 302/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3324 - accuracy: 0.5069 - val_loss: 1.5645 - val_accuracy: 0.4403\n",
            "Epoch 303/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3421 - accuracy: 0.5017 - val_loss: 1.5642 - val_accuracy: 0.4428\n",
            "Epoch 304/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3464 - accuracy: 0.5226 - val_loss: 1.5652 - val_accuracy: 0.4440\n",
            "Epoch 305/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3463 - accuracy: 0.5106 - val_loss: 1.5650 - val_accuracy: 0.4342\n",
            "Epoch 306/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3350 - accuracy: 0.5069 - val_loss: 1.5681 - val_accuracy: 0.4391\n",
            "Epoch 307/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3611 - accuracy: 0.4912 - val_loss: 1.5643 - val_accuracy: 0.4391\n",
            "Epoch 308/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3517 - accuracy: 0.5125 - val_loss: 1.5624 - val_accuracy: 0.4367\n",
            "Epoch 309/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3476 - accuracy: 0.5112 - val_loss: 1.5647 - val_accuracy: 0.4379\n",
            "Epoch 310/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3373 - accuracy: 0.5075 - val_loss: 1.5645 - val_accuracy: 0.4354\n",
            "Epoch 311/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3350 - accuracy: 0.5152 - val_loss: 1.5587 - val_accuracy: 0.4477\n",
            "Epoch 312/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3320 - accuracy: 0.5103 - val_loss: 1.5649 - val_accuracy: 0.4367\n",
            "Epoch 313/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3371 - accuracy: 0.5066 - val_loss: 1.5656 - val_accuracy: 0.4342\n",
            "Epoch 314/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3332 - accuracy: 0.5023 - val_loss: 1.5649 - val_accuracy: 0.4354\n",
            "Epoch 315/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3443 - accuracy: 0.5060 - val_loss: 1.5676 - val_accuracy: 0.4367\n",
            "Epoch 316/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3258 - accuracy: 0.5091 - val_loss: 1.5703 - val_accuracy: 0.4379\n",
            "Epoch 317/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3277 - accuracy: 0.5208 - val_loss: 1.5728 - val_accuracy: 0.4428\n",
            "Epoch 318/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3355 - accuracy: 0.5125 - val_loss: 1.5738 - val_accuracy: 0.4330\n",
            "Epoch 319/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3352 - accuracy: 0.5171 - val_loss: 1.5743 - val_accuracy: 0.4367\n",
            "Epoch 320/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3468 - accuracy: 0.5143 - val_loss: 1.5731 - val_accuracy: 0.4342\n",
            "Epoch 321/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3288 - accuracy: 0.5069 - val_loss: 1.5687 - val_accuracy: 0.4367\n",
            "Epoch 322/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3658 - accuracy: 0.5008 - val_loss: 1.5648 - val_accuracy: 0.4465\n",
            "Epoch 323/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3258 - accuracy: 0.5208 - val_loss: 1.5646 - val_accuracy: 0.4416\n",
            "Epoch 324/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3346 - accuracy: 0.5060 - val_loss: 1.5683 - val_accuracy: 0.4391\n",
            "Epoch 325/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3273 - accuracy: 0.5199 - val_loss: 1.5672 - val_accuracy: 0.4342\n",
            "Epoch 326/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3348 - accuracy: 0.5140 - val_loss: 1.5665 - val_accuracy: 0.4354\n",
            "Epoch 327/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3377 - accuracy: 0.5097 - val_loss: 1.5662 - val_accuracy: 0.4379\n",
            "Epoch 328/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3543 - accuracy: 0.5054 - val_loss: 1.5683 - val_accuracy: 0.4354\n",
            "Epoch 329/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3167 - accuracy: 0.5232 - val_loss: 1.5643 - val_accuracy: 0.4367\n",
            "Epoch 330/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3314 - accuracy: 0.5112 - val_loss: 1.5697 - val_accuracy: 0.4342\n",
            "Epoch 331/600\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 1.3391 - accuracy: 0.5051 - val_loss: 1.5700 - val_accuracy: 0.4416\n",
            "Epoch 332/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3289 - accuracy: 0.5038 - val_loss: 1.5691 - val_accuracy: 0.4403\n",
            "Epoch 333/600\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 1.3359 - accuracy: 0.5072 - val_loss: 1.5633 - val_accuracy: 0.4440\n",
            "Epoch 334/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3382 - accuracy: 0.5100 - val_loss: 1.5687 - val_accuracy: 0.4428\n",
            "Epoch 335/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3325 - accuracy: 0.5128 - val_loss: 1.5694 - val_accuracy: 0.4354\n",
            "Epoch 336/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3266 - accuracy: 0.5106 - val_loss: 1.5748 - val_accuracy: 0.4379\n",
            "Epoch 337/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3379 - accuracy: 0.5091 - val_loss: 1.5678 - val_accuracy: 0.4391\n",
            "Epoch 338/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3368 - accuracy: 0.5048 - val_loss: 1.5690 - val_accuracy: 0.4367\n",
            "Epoch 339/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3401 - accuracy: 0.5115 - val_loss: 1.5697 - val_accuracy: 0.4354\n",
            "Epoch 340/600\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 1.3391 - accuracy: 0.5118 - val_loss: 1.5670 - val_accuracy: 0.4379\n",
            "Epoch 341/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3454 - accuracy: 0.5097 - val_loss: 1.5639 - val_accuracy: 0.4416\n",
            "Epoch 342/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3314 - accuracy: 0.5122 - val_loss: 1.5610 - val_accuracy: 0.4330\n",
            "Epoch 343/600\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 1.3285 - accuracy: 0.5171 - val_loss: 1.5705 - val_accuracy: 0.4354\n",
            "Epoch 344/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3347 - accuracy: 0.5177 - val_loss: 1.5714 - val_accuracy: 0.4317\n",
            "Epoch 345/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3262 - accuracy: 0.5125 - val_loss: 1.5673 - val_accuracy: 0.4379\n",
            "Epoch 346/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3339 - accuracy: 0.5159 - val_loss: 1.5658 - val_accuracy: 0.4354\n",
            "Epoch 347/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3288 - accuracy: 0.5137 - val_loss: 1.5705 - val_accuracy: 0.4367\n",
            "Epoch 348/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3375 - accuracy: 0.5177 - val_loss: 1.5748 - val_accuracy: 0.4367\n",
            "Epoch 349/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3312 - accuracy: 0.5140 - val_loss: 1.5695 - val_accuracy: 0.4391\n",
            "Epoch 350/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3492 - accuracy: 0.5100 - val_loss: 1.5694 - val_accuracy: 0.4428\n",
            "Epoch 351/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3177 - accuracy: 0.5214 - val_loss: 1.5716 - val_accuracy: 0.4391\n",
            "Epoch 352/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3294 - accuracy: 0.5162 - val_loss: 1.5728 - val_accuracy: 0.4403\n",
            "Epoch 353/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3300 - accuracy: 0.5140 - val_loss: 1.5730 - val_accuracy: 0.4379\n",
            "Epoch 354/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3102 - accuracy: 0.5208 - val_loss: 1.5748 - val_accuracy: 0.4391\n",
            "Epoch 355/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3142 - accuracy: 0.5183 - val_loss: 1.5754 - val_accuracy: 0.4391\n",
            "Epoch 356/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3358 - accuracy: 0.5106 - val_loss: 1.5668 - val_accuracy: 0.4428\n",
            "Epoch 357/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3247 - accuracy: 0.5115 - val_loss: 1.5731 - val_accuracy: 0.4403\n",
            "Epoch 358/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3237 - accuracy: 0.5195 - val_loss: 1.5704 - val_accuracy: 0.4367\n",
            "Epoch 359/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3373 - accuracy: 0.5045 - val_loss: 1.5708 - val_accuracy: 0.4440\n",
            "Epoch 360/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3191 - accuracy: 0.5115 - val_loss: 1.5703 - val_accuracy: 0.4379\n",
            "Epoch 361/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3271 - accuracy: 0.5186 - val_loss: 1.5710 - val_accuracy: 0.4391\n",
            "Epoch 362/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3206 - accuracy: 0.5214 - val_loss: 1.5726 - val_accuracy: 0.4403\n",
            "Epoch 363/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3253 - accuracy: 0.5075 - val_loss: 1.5736 - val_accuracy: 0.4403\n",
            "Epoch 364/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3210 - accuracy: 0.5183 - val_loss: 1.5748 - val_accuracy: 0.4354\n",
            "Epoch 365/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3303 - accuracy: 0.5128 - val_loss: 1.5703 - val_accuracy: 0.4342\n",
            "Epoch 366/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3244 - accuracy: 0.5122 - val_loss: 1.5701 - val_accuracy: 0.4391\n",
            "Epoch 367/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3346 - accuracy: 0.5180 - val_loss: 1.5754 - val_accuracy: 0.4379\n",
            "Epoch 368/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3204 - accuracy: 0.5134 - val_loss: 1.5720 - val_accuracy: 0.4403\n",
            "Epoch 369/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3260 - accuracy: 0.5177 - val_loss: 1.5741 - val_accuracy: 0.4293\n",
            "Epoch 370/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3259 - accuracy: 0.5165 - val_loss: 1.5752 - val_accuracy: 0.4367\n",
            "Epoch 371/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3228 - accuracy: 0.5115 - val_loss: 1.5758 - val_accuracy: 0.4379\n",
            "Epoch 372/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3181 - accuracy: 0.5214 - val_loss: 1.5802 - val_accuracy: 0.4403\n",
            "Epoch 373/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3312 - accuracy: 0.5075 - val_loss: 1.5737 - val_accuracy: 0.4403\n",
            "Epoch 374/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3108 - accuracy: 0.5239 - val_loss: 1.5712 - val_accuracy: 0.4440\n",
            "Epoch 375/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3129 - accuracy: 0.5137 - val_loss: 1.5724 - val_accuracy: 0.4428\n",
            "Epoch 376/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3120 - accuracy: 0.5168 - val_loss: 1.5719 - val_accuracy: 0.4465\n",
            "Epoch 377/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3143 - accuracy: 0.5149 - val_loss: 1.5738 - val_accuracy: 0.4428\n",
            "Epoch 378/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3283 - accuracy: 0.5183 - val_loss: 1.5731 - val_accuracy: 0.4342\n",
            "Epoch 379/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3187 - accuracy: 0.5165 - val_loss: 1.5703 - val_accuracy: 0.4379\n",
            "Epoch 380/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3354 - accuracy: 0.5078 - val_loss: 1.5666 - val_accuracy: 0.4428\n",
            "Epoch 381/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3275 - accuracy: 0.5118 - val_loss: 1.5683 - val_accuracy: 0.4403\n",
            "Epoch 382/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3208 - accuracy: 0.5137 - val_loss: 1.5675 - val_accuracy: 0.4379\n",
            "Epoch 383/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3102 - accuracy: 0.5165 - val_loss: 1.5720 - val_accuracy: 0.4354\n",
            "Epoch 384/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3254 - accuracy: 0.5125 - val_loss: 1.5732 - val_accuracy: 0.4379\n",
            "Epoch 385/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3143 - accuracy: 0.5208 - val_loss: 1.5700 - val_accuracy: 0.4379\n",
            "Epoch 386/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3208 - accuracy: 0.5091 - val_loss: 1.5714 - val_accuracy: 0.4367\n",
            "Epoch 387/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3157 - accuracy: 0.5159 - val_loss: 1.5762 - val_accuracy: 0.4330\n",
            "Epoch 388/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3254 - accuracy: 0.5159 - val_loss: 1.5680 - val_accuracy: 0.4330\n",
            "Epoch 389/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3337 - accuracy: 0.5143 - val_loss: 1.5692 - val_accuracy: 0.4416\n",
            "Epoch 390/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3118 - accuracy: 0.5192 - val_loss: 1.5730 - val_accuracy: 0.4391\n",
            "Epoch 391/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3225 - accuracy: 0.5174 - val_loss: 1.5695 - val_accuracy: 0.4379\n",
            "Epoch 392/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3228 - accuracy: 0.5097 - val_loss: 1.5718 - val_accuracy: 0.4354\n",
            "Epoch 393/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3219 - accuracy: 0.5195 - val_loss: 1.5692 - val_accuracy: 0.4379\n",
            "Epoch 394/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3325 - accuracy: 0.5066 - val_loss: 1.5691 - val_accuracy: 0.4391\n",
            "Epoch 395/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3152 - accuracy: 0.5137 - val_loss: 1.5744 - val_accuracy: 0.4403\n",
            "Epoch 396/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3184 - accuracy: 0.5134 - val_loss: 1.5708 - val_accuracy: 0.4391\n",
            "Epoch 397/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3246 - accuracy: 0.5152 - val_loss: 1.5703 - val_accuracy: 0.4367\n",
            "Epoch 398/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3219 - accuracy: 0.5202 - val_loss: 1.5666 - val_accuracy: 0.4428\n",
            "Epoch 399/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3181 - accuracy: 0.5085 - val_loss: 1.5686 - val_accuracy: 0.4440\n",
            "Epoch 400/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3144 - accuracy: 0.5202 - val_loss: 1.5674 - val_accuracy: 0.4367\n",
            "Epoch 401/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3208 - accuracy: 0.5189 - val_loss: 1.5740 - val_accuracy: 0.4379\n",
            "Epoch 402/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3220 - accuracy: 0.5149 - val_loss: 1.5729 - val_accuracy: 0.4391\n",
            "Epoch 403/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3098 - accuracy: 0.5195 - val_loss: 1.5713 - val_accuracy: 0.4428\n",
            "Epoch 404/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3182 - accuracy: 0.5260 - val_loss: 1.5704 - val_accuracy: 0.4440\n",
            "Epoch 405/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3110 - accuracy: 0.5097 - val_loss: 1.5684 - val_accuracy: 0.4391\n",
            "Epoch 406/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3113 - accuracy: 0.5128 - val_loss: 1.5706 - val_accuracy: 0.4379\n",
            "Epoch 407/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3053 - accuracy: 0.5248 - val_loss: 1.5729 - val_accuracy: 0.4354\n",
            "Epoch 408/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3051 - accuracy: 0.5143 - val_loss: 1.5708 - val_accuracy: 0.4416\n",
            "Epoch 409/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3104 - accuracy: 0.5251 - val_loss: 1.5735 - val_accuracy: 0.4354\n",
            "Epoch 410/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3158 - accuracy: 0.5103 - val_loss: 1.5761 - val_accuracy: 0.4330\n",
            "Epoch 411/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3239 - accuracy: 0.5103 - val_loss: 1.5755 - val_accuracy: 0.4391\n",
            "Epoch 412/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3137 - accuracy: 0.5152 - val_loss: 1.5723 - val_accuracy: 0.4379\n",
            "Epoch 413/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3133 - accuracy: 0.5263 - val_loss: 1.5674 - val_accuracy: 0.4453\n",
            "Epoch 414/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3016 - accuracy: 0.5115 - val_loss: 1.5688 - val_accuracy: 0.4391\n",
            "Epoch 415/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3115 - accuracy: 0.5217 - val_loss: 1.5725 - val_accuracy: 0.4391\n",
            "Epoch 416/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2980 - accuracy: 0.5226 - val_loss: 1.5746 - val_accuracy: 0.4391\n",
            "Epoch 417/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3109 - accuracy: 0.5134 - val_loss: 1.5714 - val_accuracy: 0.4416\n",
            "Epoch 418/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3022 - accuracy: 0.5192 - val_loss: 1.5703 - val_accuracy: 0.4428\n",
            "Epoch 419/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3124 - accuracy: 0.5082 - val_loss: 1.5753 - val_accuracy: 0.4330\n",
            "Epoch 420/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3187 - accuracy: 0.5118 - val_loss: 1.5752 - val_accuracy: 0.4354\n",
            "Epoch 421/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2969 - accuracy: 0.5199 - val_loss: 1.5791 - val_accuracy: 0.4342\n",
            "Epoch 422/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3225 - accuracy: 0.5229 - val_loss: 1.5745 - val_accuracy: 0.4354\n",
            "Epoch 423/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3122 - accuracy: 0.5159 - val_loss: 1.5775 - val_accuracy: 0.4317\n",
            "Epoch 424/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2958 - accuracy: 0.5202 - val_loss: 1.5777 - val_accuracy: 0.4428\n",
            "Epoch 425/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3093 - accuracy: 0.5202 - val_loss: 1.5744 - val_accuracy: 0.4330\n",
            "Epoch 426/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3204 - accuracy: 0.5155 - val_loss: 1.5764 - val_accuracy: 0.4367\n",
            "Epoch 427/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3066 - accuracy: 0.5251 - val_loss: 1.5760 - val_accuracy: 0.4342\n",
            "Epoch 428/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3024 - accuracy: 0.5162 - val_loss: 1.5771 - val_accuracy: 0.4391\n",
            "Epoch 429/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3083 - accuracy: 0.5189 - val_loss: 1.5783 - val_accuracy: 0.4391\n",
            "Epoch 430/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3057 - accuracy: 0.5186 - val_loss: 1.5735 - val_accuracy: 0.4403\n",
            "Epoch 431/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3108 - accuracy: 0.5272 - val_loss: 1.5732 - val_accuracy: 0.4428\n",
            "Epoch 432/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3086 - accuracy: 0.5165 - val_loss: 1.5757 - val_accuracy: 0.4440\n",
            "Epoch 433/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2932 - accuracy: 0.5195 - val_loss: 1.5699 - val_accuracy: 0.4367\n",
            "Epoch 434/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2860 - accuracy: 0.5306 - val_loss: 1.5756 - val_accuracy: 0.4379\n",
            "Epoch 435/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3134 - accuracy: 0.5180 - val_loss: 1.5786 - val_accuracy: 0.4428\n",
            "Epoch 436/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3116 - accuracy: 0.5100 - val_loss: 1.5762 - val_accuracy: 0.4391\n",
            "Epoch 437/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3098 - accuracy: 0.5214 - val_loss: 1.5764 - val_accuracy: 0.4416\n",
            "Epoch 438/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3061 - accuracy: 0.5254 - val_loss: 1.5808 - val_accuracy: 0.4391\n",
            "Epoch 439/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2981 - accuracy: 0.5279 - val_loss: 1.5826 - val_accuracy: 0.4416\n",
            "Epoch 440/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3012 - accuracy: 0.5272 - val_loss: 1.5732 - val_accuracy: 0.4453\n",
            "Epoch 441/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3026 - accuracy: 0.5232 - val_loss: 1.5721 - val_accuracy: 0.4465\n",
            "Epoch 442/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3139 - accuracy: 0.5171 - val_loss: 1.5703 - val_accuracy: 0.4428\n",
            "Epoch 443/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2962 - accuracy: 0.5140 - val_loss: 1.5772 - val_accuracy: 0.4428\n",
            "Epoch 444/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2979 - accuracy: 0.5205 - val_loss: 1.5775 - val_accuracy: 0.4465\n",
            "Epoch 445/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3072 - accuracy: 0.5229 - val_loss: 1.5750 - val_accuracy: 0.4416\n",
            "Epoch 446/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.3097 - accuracy: 0.5177 - val_loss: 1.5737 - val_accuracy: 0.4416\n",
            "Epoch 447/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.2866 - accuracy: 0.5349 - val_loss: 1.5745 - val_accuracy: 0.4403\n",
            "Epoch 448/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.2830 - accuracy: 0.5266 - val_loss: 1.5773 - val_accuracy: 0.4465\n",
            "Epoch 449/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3062 - accuracy: 0.5168 - val_loss: 1.5749 - val_accuracy: 0.4428\n",
            "Epoch 450/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2954 - accuracy: 0.5245 - val_loss: 1.5780 - val_accuracy: 0.4440\n",
            "Epoch 451/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3020 - accuracy: 0.5229 - val_loss: 1.5754 - val_accuracy: 0.4440\n",
            "Epoch 452/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2933 - accuracy: 0.5275 - val_loss: 1.5751 - val_accuracy: 0.4477\n",
            "Epoch 453/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3003 - accuracy: 0.5220 - val_loss: 1.5788 - val_accuracy: 0.4490\n",
            "Epoch 454/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2993 - accuracy: 0.5303 - val_loss: 1.5818 - val_accuracy: 0.4428\n",
            "Epoch 455/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3065 - accuracy: 0.5186 - val_loss: 1.5817 - val_accuracy: 0.4367\n",
            "Epoch 456/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3012 - accuracy: 0.5242 - val_loss: 1.5789 - val_accuracy: 0.4403\n",
            "Epoch 457/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2888 - accuracy: 0.5195 - val_loss: 1.5793 - val_accuracy: 0.4354\n",
            "Epoch 458/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2950 - accuracy: 0.5291 - val_loss: 1.5811 - val_accuracy: 0.4403\n",
            "Epoch 459/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3063 - accuracy: 0.5177 - val_loss: 1.5768 - val_accuracy: 0.4379\n",
            "Epoch 460/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2924 - accuracy: 0.5263 - val_loss: 1.5843 - val_accuracy: 0.4330\n",
            "Epoch 461/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3084 - accuracy: 0.5340 - val_loss: 1.5814 - val_accuracy: 0.4330\n",
            "Epoch 462/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2896 - accuracy: 0.5229 - val_loss: 1.5820 - val_accuracy: 0.4391\n",
            "Epoch 463/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3080 - accuracy: 0.5094 - val_loss: 1.5832 - val_accuracy: 0.4403\n",
            "Epoch 464/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2991 - accuracy: 0.5165 - val_loss: 1.5838 - val_accuracy: 0.4403\n",
            "Epoch 465/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2893 - accuracy: 0.5242 - val_loss: 1.5799 - val_accuracy: 0.4465\n",
            "Epoch 466/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2874 - accuracy: 0.5183 - val_loss: 1.5771 - val_accuracy: 0.4453\n",
            "Epoch 467/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2800 - accuracy: 0.5248 - val_loss: 1.5780 - val_accuracy: 0.4416\n",
            "Epoch 468/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2858 - accuracy: 0.5235 - val_loss: 1.5848 - val_accuracy: 0.4416\n",
            "Epoch 469/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3058 - accuracy: 0.5220 - val_loss: 1.5779 - val_accuracy: 0.4440\n",
            "Epoch 470/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3002 - accuracy: 0.5220 - val_loss: 1.5799 - val_accuracy: 0.4403\n",
            "Epoch 471/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3000 - accuracy: 0.5208 - val_loss: 1.5777 - val_accuracy: 0.4403\n",
            "Epoch 472/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2941 - accuracy: 0.5223 - val_loss: 1.5777 - val_accuracy: 0.4440\n",
            "Epoch 473/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3084 - accuracy: 0.5257 - val_loss: 1.5773 - val_accuracy: 0.4403\n",
            "Epoch 474/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2867 - accuracy: 0.5269 - val_loss: 1.5782 - val_accuracy: 0.4354\n",
            "Epoch 475/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3048 - accuracy: 0.5235 - val_loss: 1.5839 - val_accuracy: 0.4403\n",
            "Epoch 476/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2877 - accuracy: 0.5248 - val_loss: 1.5854 - val_accuracy: 0.4403\n",
            "Epoch 477/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2927 - accuracy: 0.5272 - val_loss: 1.5877 - val_accuracy: 0.4440\n",
            "Epoch 478/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2643 - accuracy: 0.5392 - val_loss: 1.5861 - val_accuracy: 0.4440\n",
            "Epoch 479/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.2782 - accuracy: 0.5288 - val_loss: 1.5893 - val_accuracy: 0.4367\n",
            "Epoch 480/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3032 - accuracy: 0.5211 - val_loss: 1.5815 - val_accuracy: 0.4440\n",
            "Epoch 481/600\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 1.2953 - accuracy: 0.5159 - val_loss: 1.5822 - val_accuracy: 0.4477\n",
            "Epoch 482/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2928 - accuracy: 0.5229 - val_loss: 1.5832 - val_accuracy: 0.4477\n",
            "Epoch 483/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2937 - accuracy: 0.5251 - val_loss: 1.5856 - val_accuracy: 0.4440\n",
            "Epoch 484/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2855 - accuracy: 0.5355 - val_loss: 1.5876 - val_accuracy: 0.4440\n",
            "Epoch 485/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.2930 - accuracy: 0.5214 - val_loss: 1.5848 - val_accuracy: 0.4477\n",
            "Epoch 486/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2813 - accuracy: 0.5352 - val_loss: 1.5872 - val_accuracy: 0.4416\n",
            "Epoch 487/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2969 - accuracy: 0.5171 - val_loss: 1.5833 - val_accuracy: 0.4416\n",
            "Epoch 488/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2996 - accuracy: 0.5159 - val_loss: 1.5850 - val_accuracy: 0.4465\n",
            "Epoch 489/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2982 - accuracy: 0.5199 - val_loss: 1.5904 - val_accuracy: 0.4453\n",
            "Epoch 490/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2889 - accuracy: 0.5223 - val_loss: 1.5939 - val_accuracy: 0.4477\n",
            "Epoch 491/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3020 - accuracy: 0.5152 - val_loss: 1.5830 - val_accuracy: 0.4453\n",
            "Epoch 492/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2796 - accuracy: 0.5334 - val_loss: 1.5828 - val_accuracy: 0.4453\n",
            "Epoch 493/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3049 - accuracy: 0.5223 - val_loss: 1.5844 - val_accuracy: 0.4403\n",
            "Epoch 494/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.2977 - accuracy: 0.5269 - val_loss: 1.5794 - val_accuracy: 0.4440\n",
            "Epoch 495/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2839 - accuracy: 0.5355 - val_loss: 1.5838 - val_accuracy: 0.4428\n",
            "Epoch 496/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2937 - accuracy: 0.5226 - val_loss: 1.5839 - val_accuracy: 0.4465\n",
            "Epoch 497/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2830 - accuracy: 0.5266 - val_loss: 1.5872 - val_accuracy: 0.4465\n",
            "Epoch 498/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2890 - accuracy: 0.5315 - val_loss: 1.5870 - val_accuracy: 0.4490\n",
            "Epoch 499/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2870 - accuracy: 0.5291 - val_loss: 1.5849 - val_accuracy: 0.4440\n",
            "Epoch 500/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2889 - accuracy: 0.5217 - val_loss: 1.5839 - val_accuracy: 0.4403\n",
            "Epoch 501/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2844 - accuracy: 0.5229 - val_loss: 1.5877 - val_accuracy: 0.4453\n",
            "Epoch 502/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2870 - accuracy: 0.5309 - val_loss: 1.5867 - val_accuracy: 0.4465\n",
            "Epoch 503/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2929 - accuracy: 0.5288 - val_loss: 1.5853 - val_accuracy: 0.4391\n",
            "Epoch 504/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2856 - accuracy: 0.5257 - val_loss: 1.5896 - val_accuracy: 0.4367\n",
            "Epoch 505/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2819 - accuracy: 0.5260 - val_loss: 1.5900 - val_accuracy: 0.4379\n",
            "Epoch 506/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2677 - accuracy: 0.5275 - val_loss: 1.5848 - val_accuracy: 0.4416\n",
            "Epoch 507/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2977 - accuracy: 0.5208 - val_loss: 1.5890 - val_accuracy: 0.4379\n",
            "Epoch 508/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2824 - accuracy: 0.5220 - val_loss: 1.5856 - val_accuracy: 0.4453\n",
            "Epoch 509/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2715 - accuracy: 0.5303 - val_loss: 1.5910 - val_accuracy: 0.4403\n",
            "Epoch 510/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2726 - accuracy: 0.5312 - val_loss: 1.5959 - val_accuracy: 0.4416\n",
            "Epoch 511/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2831 - accuracy: 0.5195 - val_loss: 1.5898 - val_accuracy: 0.4440\n",
            "Epoch 512/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2773 - accuracy: 0.5245 - val_loss: 1.5888 - val_accuracy: 0.4416\n",
            "Epoch 513/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3021 - accuracy: 0.5168 - val_loss: 1.5892 - val_accuracy: 0.4403\n",
            "Epoch 514/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2828 - accuracy: 0.5315 - val_loss: 1.5925 - val_accuracy: 0.4367\n",
            "Epoch 515/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.3016 - accuracy: 0.5257 - val_loss: 1.5927 - val_accuracy: 0.4379\n",
            "Epoch 516/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2929 - accuracy: 0.5248 - val_loss: 1.5900 - val_accuracy: 0.4391\n",
            "Epoch 517/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2733 - accuracy: 0.5266 - val_loss: 1.5926 - val_accuracy: 0.4428\n",
            "Epoch 518/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2734 - accuracy: 0.5211 - val_loss: 1.5918 - val_accuracy: 0.4379\n",
            "Epoch 519/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2777 - accuracy: 0.5306 - val_loss: 1.5956 - val_accuracy: 0.4428\n",
            "Epoch 520/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2848 - accuracy: 0.5229 - val_loss: 1.5940 - val_accuracy: 0.4428\n",
            "Epoch 521/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.2785 - accuracy: 0.5235 - val_loss: 1.5966 - val_accuracy: 0.4391\n",
            "Epoch 522/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.2603 - accuracy: 0.5340 - val_loss: 1.5949 - val_accuracy: 0.4403\n",
            "Epoch 523/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2826 - accuracy: 0.5254 - val_loss: 1.5963 - val_accuracy: 0.4428\n",
            "Epoch 524/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2807 - accuracy: 0.5340 - val_loss: 1.5896 - val_accuracy: 0.4453\n",
            "Epoch 525/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2761 - accuracy: 0.5275 - val_loss: 1.5919 - val_accuracy: 0.4465\n",
            "Epoch 526/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.3014 - accuracy: 0.5208 - val_loss: 1.5941 - val_accuracy: 0.4440\n",
            "Epoch 527/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.2631 - accuracy: 0.5297 - val_loss: 1.5910 - val_accuracy: 0.4428\n",
            "Epoch 528/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.3056 - accuracy: 0.5177 - val_loss: 1.5916 - val_accuracy: 0.4379\n",
            "Epoch 529/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.2664 - accuracy: 0.5300 - val_loss: 1.5916 - val_accuracy: 0.4379\n",
            "Epoch 530/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2822 - accuracy: 0.5248 - val_loss: 1.5890 - val_accuracy: 0.4391\n",
            "Epoch 531/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2817 - accuracy: 0.5229 - val_loss: 1.5910 - val_accuracy: 0.4428\n",
            "Epoch 532/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.3001 - accuracy: 0.5192 - val_loss: 1.5901 - val_accuracy: 0.4440\n",
            "Epoch 533/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2758 - accuracy: 0.5315 - val_loss: 1.5888 - val_accuracy: 0.4391\n",
            "Epoch 534/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2771 - accuracy: 0.5248 - val_loss: 1.5947 - val_accuracy: 0.4342\n",
            "Epoch 535/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2879 - accuracy: 0.5232 - val_loss: 1.5906 - val_accuracy: 0.4367\n",
            "Epoch 536/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2734 - accuracy: 0.5346 - val_loss: 1.5917 - val_accuracy: 0.4403\n",
            "Epoch 537/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2759 - accuracy: 0.5223 - val_loss: 1.5944 - val_accuracy: 0.4403\n",
            "Epoch 538/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2696 - accuracy: 0.5312 - val_loss: 1.5975 - val_accuracy: 0.4440\n",
            "Epoch 539/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2742 - accuracy: 0.5343 - val_loss: 1.5937 - val_accuracy: 0.4428\n",
            "Epoch 540/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2702 - accuracy: 0.5300 - val_loss: 1.5969 - val_accuracy: 0.4391\n",
            "Epoch 541/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2838 - accuracy: 0.5199 - val_loss: 1.5929 - val_accuracy: 0.4391\n",
            "Epoch 542/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.2759 - accuracy: 0.5275 - val_loss: 1.5939 - val_accuracy: 0.4440\n",
            "Epoch 543/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2999 - accuracy: 0.5199 - val_loss: 1.5963 - val_accuracy: 0.4428\n",
            "Epoch 544/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2737 - accuracy: 0.5248 - val_loss: 1.6004 - val_accuracy: 0.4403\n",
            "Epoch 545/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2799 - accuracy: 0.5248 - val_loss: 1.5970 - val_accuracy: 0.4354\n",
            "Epoch 546/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2849 - accuracy: 0.5269 - val_loss: 1.5950 - val_accuracy: 0.4403\n",
            "Epoch 547/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2671 - accuracy: 0.5349 - val_loss: 1.5954 - val_accuracy: 0.4367\n",
            "Epoch 548/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2671 - accuracy: 0.5374 - val_loss: 1.5940 - val_accuracy: 0.4391\n",
            "Epoch 549/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2838 - accuracy: 0.5192 - val_loss: 1.5932 - val_accuracy: 0.4391\n",
            "Epoch 550/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2709 - accuracy: 0.5232 - val_loss: 1.5913 - val_accuracy: 0.4379\n",
            "Epoch 551/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2843 - accuracy: 0.5232 - val_loss: 1.5979 - val_accuracy: 0.4354\n",
            "Epoch 552/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2728 - accuracy: 0.5303 - val_loss: 1.5995 - val_accuracy: 0.4367\n",
            "Epoch 553/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2749 - accuracy: 0.5371 - val_loss: 1.5935 - val_accuracy: 0.4354\n",
            "Epoch 554/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2883 - accuracy: 0.5242 - val_loss: 1.5867 - val_accuracy: 0.4367\n",
            "Epoch 555/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2677 - accuracy: 0.5315 - val_loss: 1.5942 - val_accuracy: 0.4416\n",
            "Epoch 556/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2706 - accuracy: 0.5306 - val_loss: 1.5981 - val_accuracy: 0.4391\n",
            "Epoch 557/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2809 - accuracy: 0.5359 - val_loss: 1.6016 - val_accuracy: 0.4403\n",
            "Epoch 558/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2773 - accuracy: 0.5266 - val_loss: 1.5942 - val_accuracy: 0.4367\n",
            "Epoch 559/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.2787 - accuracy: 0.5297 - val_loss: 1.6009 - val_accuracy: 0.4342\n",
            "Epoch 560/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.2735 - accuracy: 0.5368 - val_loss: 1.5950 - val_accuracy: 0.4342\n",
            "Epoch 561/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.2679 - accuracy: 0.5334 - val_loss: 1.5936 - val_accuracy: 0.4391\n",
            "Epoch 562/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.2998 - accuracy: 0.5140 - val_loss: 1.5955 - val_accuracy: 0.4403\n",
            "Epoch 563/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2804 - accuracy: 0.5279 - val_loss: 1.5966 - val_accuracy: 0.4416\n",
            "Epoch 564/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2750 - accuracy: 0.5362 - val_loss: 1.5938 - val_accuracy: 0.4416\n",
            "Epoch 565/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2561 - accuracy: 0.5352 - val_loss: 1.5942 - val_accuracy: 0.4379\n",
            "Epoch 566/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2764 - accuracy: 0.5297 - val_loss: 1.5956 - val_accuracy: 0.4391\n",
            "Epoch 567/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2909 - accuracy: 0.5257 - val_loss: 1.5982 - val_accuracy: 0.4379\n",
            "Epoch 568/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2629 - accuracy: 0.5389 - val_loss: 1.6035 - val_accuracy: 0.4330\n",
            "Epoch 569/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2696 - accuracy: 0.5263 - val_loss: 1.6002 - val_accuracy: 0.4330\n",
            "Epoch 570/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2751 - accuracy: 0.5275 - val_loss: 1.5946 - val_accuracy: 0.4330\n",
            "Epoch 571/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2550 - accuracy: 0.5414 - val_loss: 1.5974 - val_accuracy: 0.4317\n",
            "Epoch 572/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2734 - accuracy: 0.5371 - val_loss: 1.6021 - val_accuracy: 0.4379\n",
            "Epoch 573/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2780 - accuracy: 0.5306 - val_loss: 1.5979 - val_accuracy: 0.4330\n",
            "Epoch 574/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2717 - accuracy: 0.5365 - val_loss: 1.5998 - val_accuracy: 0.4367\n",
            "Epoch 575/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2823 - accuracy: 0.5275 - val_loss: 1.5987 - val_accuracy: 0.4379\n",
            "Epoch 576/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2723 - accuracy: 0.5272 - val_loss: 1.6010 - val_accuracy: 0.4354\n",
            "Epoch 577/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.2712 - accuracy: 0.5343 - val_loss: 1.6067 - val_accuracy: 0.4330\n",
            "Epoch 578/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.2660 - accuracy: 0.5309 - val_loss: 1.6024 - val_accuracy: 0.4379\n",
            "Epoch 579/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.2680 - accuracy: 0.5331 - val_loss: 1.6043 - val_accuracy: 0.4391\n",
            "Epoch 580/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2605 - accuracy: 0.5291 - val_loss: 1.6041 - val_accuracy: 0.4342\n",
            "Epoch 581/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2759 - accuracy: 0.5263 - val_loss: 1.6060 - val_accuracy: 0.4342\n",
            "Epoch 582/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2671 - accuracy: 0.5359 - val_loss: 1.5993 - val_accuracy: 0.4367\n",
            "Epoch 583/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.2688 - accuracy: 0.5232 - val_loss: 1.5979 - val_accuracy: 0.4379\n",
            "Epoch 584/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.2744 - accuracy: 0.5362 - val_loss: 1.6019 - val_accuracy: 0.4342\n",
            "Epoch 585/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2773 - accuracy: 0.5303 - val_loss: 1.5995 - val_accuracy: 0.4403\n",
            "Epoch 586/600\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 1.2649 - accuracy: 0.5315 - val_loss: 1.5996 - val_accuracy: 0.4440\n",
            "Epoch 587/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.2793 - accuracy: 0.5309 - val_loss: 1.6042 - val_accuracy: 0.4317\n",
            "Epoch 588/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2643 - accuracy: 0.5399 - val_loss: 1.6066 - val_accuracy: 0.4367\n",
            "Epoch 589/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2545 - accuracy: 0.5405 - val_loss: 1.6007 - val_accuracy: 0.4391\n",
            "Epoch 590/600\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.5306 - val_loss: 1.6008 - val_accuracy: 0.4453\n",
            "Epoch 591/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2783 - accuracy: 0.5263 - val_loss: 1.5996 - val_accuracy: 0.4440\n",
            "Epoch 592/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2642 - accuracy: 0.5426 - val_loss: 1.6021 - val_accuracy: 0.4416\n",
            "Epoch 593/600\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 1.2688 - accuracy: 0.5349 - val_loss: 1.6027 - val_accuracy: 0.4416\n",
            "Epoch 594/600\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 1.2582 - accuracy: 0.5337 - val_loss: 1.6055 - val_accuracy: 0.4391\n",
            "Epoch 595/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2596 - accuracy: 0.5374 - val_loss: 1.6058 - val_accuracy: 0.4379\n",
            "Epoch 596/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2594 - accuracy: 0.5414 - val_loss: 1.6052 - val_accuracy: 0.4391\n",
            "Epoch 597/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2619 - accuracy: 0.5346 - val_loss: 1.6013 - val_accuracy: 0.4317\n",
            "Epoch 598/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2601 - accuracy: 0.5312 - val_loss: 1.6034 - val_accuracy: 0.4428\n",
            "Epoch 599/600\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 1.2624 - accuracy: 0.5405 - val_loss: 1.6077 - val_accuracy: 0.4391\n",
            "Epoch 600/600\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 1.2737 - accuracy: 0.5239 - val_loss: 1.6087 - val_accuracy: 0.4367\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x796c2b7009a0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Accuracy: {scores[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFMjwFnVQyRx",
        "outputId": "f6b7e7ac-5b83-4ce2-ed40-86532a4c72ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 43.665435910224915%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict classes\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate F1 score for each class\n",
        "f1_scores = f1_score(y_true_classes, y_pred_classes, average=None)  # Returns an array of F1 scores for each class\n",
        "\n",
        "# Print F1 scores for each class\n",
        "for idx, f1 in enumerate(f1_scores):\n",
        "    print(f'F1 Score for Class {idx}: {f1:.4f}')\n",
        "\n",
        "# Optionally, print a full classification report\n",
        "print(classification_report(y_true_classes, y_pred_classes))"
      ],
      "metadata": {
        "id": "3KjrTAD9RCZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ba9531-3124-488e-b732-f0bcbfa8d66b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 1s 3ms/step\n",
            "F1 Score for Class 0: 0.0000\n",
            "F1 Score for Class 1: 0.1967\n",
            "F1 Score for Class 2: 0.1562\n",
            "F1 Score for Class 3: 0.2676\n",
            "F1 Score for Class 4: 0.0000\n",
            "F1 Score for Class 5: 0.0000\n",
            "F1 Score for Class 6: 0.3857\n",
            "F1 Score for Class 7: 0.6132\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        10\n",
            "           2       0.26      0.16      0.20        75\n",
            "           3       0.26      0.11      0.16        90\n",
            "           4       0.47      0.19      0.27       102\n",
            "           5       0.00      0.00      0.00        72\n",
            "           6       0.00      0.00      0.00         9\n",
            "           7       0.35      0.43      0.39       126\n",
            "           8       0.50      0.79      0.61       329\n",
            "\n",
            "    accuracy                           0.44       813\n",
            "   macro avg       0.23      0.21      0.20       813\n",
            "weighted avg       0.37      0.44      0.38       813\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mi6f_IKgc4jD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}